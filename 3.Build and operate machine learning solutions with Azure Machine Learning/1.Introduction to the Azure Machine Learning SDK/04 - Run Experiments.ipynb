{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Run Experiments\n",
        "\n",
        "You can use the Azure Machine Learning SDK to run code experiments that log metrics and generate outputs. This is at the core of most machine learning operations in Azure Machine Learning.\n",
        "\n",
        "## Connect to your workspace\n",
        "\n",
        "All experiments and associated resources are managed within your Azure Machine Learning workspace. In most cases, you should store the workspace configuration in a JSON configuration file. This makes it easier to reconnect without needing to remember details like your Azure subscription ID. You can download the JSON configuration file from the blade for your workspace in the Azure portal, but if you're using a Compute Instance within your workspace, the configuration file has already been downloaded to the root folder.\n",
        "\n",
        "The code below uses the configuration file to connect to your workspace.\n",
        "\n",
        "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.44.0 to work with exercise_deep_neural_network\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1665910617642
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run an experiment\n",
        "\n",
        "One of the most fundamental tasks that data scientists need to perform is to create and run experiments that process and analyze data. In this exercise, you'll learn how to use an Azure ML *experiment* to run Python code and record values extracted from data. In this case, you'll use a simple dataset that contains details of patients that have been tested for diabetes. You'll run an experiment to explore the data, extracting statistics, visualizations, and data samples. Most of the code you'll use is fairly generic Python, such as you might run in any data exploration process. However, with the addition of a few lines, the code uses an Azure ML *experiment* to log details of the run."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "# Create an Azure ML experiment in your workspace\n",
        "experiment = Experiment(workspace=ws, name=\"mslearn-diabetes\")\n",
        "\n",
        "# Start logging data from the experiment, obtaining a reference to the experiment run\n",
        "run = experiment.start_logging()\n",
        "print(\"Starting experiment:\", experiment.name)\n",
        "\n",
        "# load the data from a local file\n",
        "data = pd.read_csv('data/diabetes.csv')\n",
        "\n",
        "# Count the rows and log the result\n",
        "row_count = (len(data))\n",
        "run.log('observations', row_count)\n",
        "print('Analyzing {} rows of data'.format(row_count))\n",
        "\n",
        "# Plot and log the count of diabetic vs non-diabetic patients\n",
        "diabetic_counts = data['Diabetic'].value_counts()\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "ax = fig.gca()    \n",
        "diabetic_counts.plot.bar(ax = ax) \n",
        "ax.set_title('Patients with Diabetes') \n",
        "ax.set_xlabel('Diagnosis') \n",
        "ax.set_ylabel('Patients')\n",
        "plt.show()\n",
        "run.log_image(name='label distribution', plot=fig)\n",
        "\n",
        "# log distinct pregnancy counts\n",
        "pregnancies = data.Pregnancies.unique()\n",
        "run.log_list('pregnancy categories', pregnancies)\n",
        "\n",
        "# Log summary statistics for numeric columns\n",
        "med_columns = ['PlasmaGlucose', 'DiastolicBloodPressure', 'TricepsThickness', 'SerumInsulin', 'BMI']\n",
        "summary_stats = data[med_columns].describe().to_dict()\n",
        "for col in summary_stats:\n",
        "    keys = list(summary_stats[col].keys())\n",
        "    values = list(summary_stats[col].values())\n",
        "    for index in range(len(keys)):\n",
        "        run.log_row(col, stat=keys[index], value = values[index])\n",
        "        \n",
        "# Save a sample of the data and upload it to the experiment output\n",
        "data.sample(100).to_csv('sample.csv', index=False, header=True)\n",
        "run.upload_file(name='outputs/sample.csv', path_or_stream='./sample.csv')\n",
        "\n",
        "# Complete the run\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Starting experiment: mslearn-diabetes\nAnalyzing 10000 rows of data\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x432 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1665910636724
        },
        "scrolled": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View run details\n",
        "\n",
        "In Jupyter Notebooks, you can use the **RunDetails** widget to see a visualization of the run details."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "\n",
        "RunDetails(run).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f19e34bc1170476d9d5befa56a47d812"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/21ed9a8a-dd0c-49f5-9327-d0fd3aa09697?wsid=/subscriptions/fe87babe-9ce9-43f8-b0aa-70603823aca8/resourcegroups/exercise_train_a_deep_neural_network/workspaces/exercise_deep_neural_network&tid=d6755233-46af-4030-8906-057bd29a9ee8\", \"run_id\": \"21ed9a8a-dd0c-49f5-9327-d0fd3aa09697\", \"run_properties\": {\"run_id\": \"21ed9a8a-dd0c-49f5-9327-d0fd3aa09697\", \"created_utc\": \"2022-10-16T08:57:04.3208Z\", \"properties\": {\"ContentSnapshotId\": \"9df14e78-52a7-4f3d-998e-b38962a9ef35\"}, \"tags\": {}, \"end_time_utc\": \"2022-10-16T08:57:16.498856Z\", \"status\": \"Completed\", \"log_files\": {}, \"log_groups\": [], \"run_duration\": \"0:00:12\", \"run_number\": \"1665910624\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"observations\", \"run_id\": \"21ed9a8a-dd0c-49f5-9327-d0fd3aa09697\", \"categories\": [0], \"series\": [{\"data\": [10000]}]}, {\"name\": \"label distribution\", \"run_id\": \"21ed9a8a-dd0c-49f5-9327-d0fd3aa09697\", \"categories\": [0], \"series\": [{\"data\": [\"aml://artifactId/ExperimentRun/dcid.21ed9a8a-dd0c-49f5-9327-d0fd3aa09697/label distribution_1665910628.png\"]}]}, {\"name\": \"pregnancy categories\", \"run_id\": \"21ed9a8a-dd0c-49f5-9327-d0fd3aa09697\", \"categories\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], \"series\": [{\"data\": [0, 8, 7, 9, 1, 3, 5, 2, 6, 11, 4, 13, 10, 12, 14]}]}, {\"name\": \"PlasmaGlucose\", \"run_id\": \"21ed9a8a-dd0c-49f5-9327-d0fd3aa09697\", \"categories\": [0], \"series\": [{\"data\": [{\"stat\": [\"count\", \"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\"], \"value\": [10000.0, 107.8502, 31.920909360565563, 44.0, 84.0, 105.0, 129.0, 192.0]}]}]}, {\"name\": \"DiastolicBloodPressure\", \"run_id\": \"21ed9a8a-dd0c-49f5-9327-d0fd3aa09697\", \"categories\": [0], \"series\": [{\"data\": [{\"stat\": [\"count\", \"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\"], \"value\": [10000.0, 71.2075, 16.801478289640706, 24.0, 58.0, 72.0, 85.0, 117.0]}]}]}, {\"name\": \"TricepsThickness\", \"run_id\": \"21ed9a8a-dd0c-49f5-9327-d0fd3aa09697\", \"categories\": [0], \"series\": [{\"data\": [{\"stat\": [\"count\", \"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\"], \"value\": [10000.0, 28.8176, 14.506480415228332, 7.0, 15.0, 31.0, 41.0, 92.0]}]}]}, {\"name\": \"SerumInsulin\", \"run_id\": \"21ed9a8a-dd0c-49f5-9327-d0fd3aa09697\", \"categories\": [0], \"series\": [{\"data\": [{\"stat\": [\"count\", \"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\"], \"value\": [10000.0, 139.2436, 133.77791937465278, 14.0, 39.0, 85.0, 197.0, 796.0]}]}]}, {\"name\": \"BMI\", \"run_id\": \"21ed9a8a-dd0c-49f5-9327-d0fd3aa09697\", \"categories\": [0], \"series\": [{\"data\": [{\"stat\": [\"count\", \"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\"], \"value\": [10000.0, 31.56702174359113, 9.804365693559113, 18.20080735, 21.247426835, 31.922420785, 39.3289214475, 56.03462763]}]}]}], \"run_logs\": \"\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.44.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1665910668105
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View more details in Azure Machine Learning studio\n",
        "\n",
        "Note that the **RunDetails** widget includes a link to **view run details** in Azure Machine Learning studio. Click this to open a new browser tab with the run details (you can also just open [Azure Machine Learning studio](https://ml.azure.com) and find the run on the **Jobs** page). When viewing the job run in Azure Machine Learning studio, note the following:\n",
        "\n",
        "- The **Overview** tab contains the general properties of the experiment run.\n",
        "- The **Metrics** tab enables you to select logged metrics and view them as tables or charts.\n",
        "- The **Images** tab enables you to select and view any images or plots that were logged in the experiment (in this case, the *Label Distribution* plot)\n",
        "- The **Child jobs** tab lists any child runs (in this experiment there are none).\n",
        "- The **Outputs + logs** tab shows the output or log files generated by the experiment.\n",
        "- The **Code** tab contains all files in the folder where the experiment code was run (in this case, everything in the same folder as this notebook).\n",
        "- The **Explanations** tab is used to show model explanations generated by the experiment (in this case, there are none).\n",
        "- The **Fairness** tab is used to visualize predictive performance disparities that help you evaluate the fairness of machine learning models (in this case, there are none)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieve experiment details using the SDK\n",
        "\n",
        "The **run** variable in the code you ran previously is an instance of a **Run** object, which is a reference to an individual run of an experiment in Azure Machine Learning. You can use this reference to get information about the run and its outputs:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Get logged metrics\n",
        "print(\"Metrics:\")\n",
        "metrics = run.get_metrics()\n",
        "for metric_name in metrics:\n",
        "    print(metric_name, \":\", metrics[metric_name])\n",
        "\n",
        "# Get output files\n",
        "print(\"\\nFiles:\")\n",
        "files = run.get_file_names()\n",
        "for file in files:\n",
        "    print(file)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Metrics:\nobservations : 10000\nlabel distribution : aml://artifactId/ExperimentRun/dcid.21ed9a8a-dd0c-49f5-9327-d0fd3aa09697/label distribution_1665910628.png\npregnancy categories : [0, 8, 7, 9, 1, 3, 5, 2, 6, 11, 4, 13, 10, 12, 14]\nPlasmaGlucose : {'stat': ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], 'value': [10000.0, 107.8502, 31.920909360565563, 44.0, 84.0, 105.0, 129.0, 192.0]}\nDiastolicBloodPressure : {'stat': ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], 'value': [10000.0, 71.2075, 16.801478289640706, 24.0, 58.0, 72.0, 85.0, 117.0]}\nTricepsThickness : {'stat': ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], 'value': [10000.0, 28.8176, 14.506480415228332, 7.0, 15.0, 31.0, 41.0, 92.0]}\nSerumInsulin : {'stat': ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], 'value': [10000.0, 139.2436, 133.77791937465278, 14.0, 39.0, 85.0, 197.0, 796.0]}\nBMI : {'stat': ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], 'value': [10000.0, 31.56702174359113, 9.804365693559113, 18.20080735, 21.247426835, 31.922420785, 39.3289214475, 56.03462763]}\n\nFiles:\nlabel distribution_1665910628.png\noutputs/sample.csv\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1665910669198
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can download the files produced by the experiment, either individually by using the **download_file** method, or by using the **download_files** method to retrieve multiple files. The following code downloads all of the files in the run's **output** folder:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "download_folder = 'downloaded-files'\n",
        "\n",
        "# Download files in the \"outputs\" folder\n",
        "run.download_files(prefix='outputs', output_directory=download_folder)\n",
        "\n",
        "# Verify the files have been downloaded\n",
        "for root, directories, filenames in os.walk(download_folder): \n",
        "    for filename in filenames:  \n",
        "        print (os.path.join(root,filename))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "downloaded-files/outputs/sample.csv\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1665910669498
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you need to troubleshoot the experiment run, you can use the **get_details** method to retrieve basic details about the run, or you can use the **get_details_with_logs** method to retrieve the run details as well as the contents of log files generated during the run:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "run.get_details_with_logs()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "{'runId': '21ed9a8a-dd0c-49f5-9327-d0fd3aa09697',\n 'target': 'local',\n 'status': 'Completed',\n 'startTimeUtc': '2022-10-16T08:57:04.643028Z',\n 'endTimeUtc': '2022-10-16T08:57:16.498856Z',\n 'services': {},\n 'properties': {'ContentSnapshotId': '9df14e78-52a7-4f3d-998e-b38962a9ef35'},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'logFiles': {},\n 'submittedBy': '형진 김'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1665910669732
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the details include information about the compute target on which the experiment was run, the date and time when it started and ended. Additionally, because the notebook containing the experiment code (this one) is in a cloned Git repository, details about the repo, branch, and status are recorded in the run history.\n",
        "\n",
        "In this case, note that the **logFiles** entry in the details indicates that no log files were generated. That's typical for an inline experiment like the one you ran, but things get more interesting when you run a script as an experiment; which is what we'll look at next."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run an experiment script\n",
        "\n",
        "In the previous example, you ran an experiment inline in this notebook. A more flexible solution is to create a separate script for the experiment, and store it in a folder along with any other files it needs, and then use Azure ML to run the experiment based on the script in the folder.\n",
        "\n",
        "First, let's create a folder for the experiment files, and copy the data into it:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "\n",
        "# Create a folder for the experiment files\n",
        "folder_name = 'diabetes-experiment-files'\n",
        "experiment_folder = './' + folder_name\n",
        "os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "# Copy the data file into the experiment folder\n",
        "shutil.copy('data/diabetes.csv', os.path.join(folder_name, \"diabetes.csv\"))"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "'diabetes-experiment-files/diabetes.csv'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1665910669959
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll create a Python script containing the code for our experiment, and save it in the experiment folder.\n",
        "\n",
        "> **Note**: running the following cell just *creates* the script file - it doesn't run it!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $folder_name/diabetes_experiment.py\n",
        "from azureml.core import Run\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the diabetes dataset\n",
        "data = pd.read_csv('diabetes.csv')\n",
        "\n",
        "# Count the rows and log the result\n",
        "row_count = (len(data))\n",
        "run.log('observations', row_count)\n",
        "print('Analyzing {} rows of data'.format(row_count))\n",
        "\n",
        "# Count and log the label counts\n",
        "diabetic_counts = data['Diabetic'].value_counts()\n",
        "print(diabetic_counts)\n",
        "for k, v in diabetic_counts.items():\n",
        "    run.log('Label:' + str(k), v)\n",
        "      \n",
        "# Save a sample of the data in the outputs folder (which gets uploaded automatically)\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "data.sample(100).to_csv(\"outputs/sample.csv\", index=False, header=True)\n",
        "\n",
        "# Complete the run\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting diabetes-experiment-files/diabetes_experiment.py\n"
        }
      ],
      "execution_count": 17,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is a simplified version of the inline code used before. However, note the following:\n",
        "- It uses the `Run.get_context()` method to retrieve the experiment run context when the script is run.\n",
        "- It loads the diabetes data from the folder where the script is located.\n",
        "- It creates a folder named **outputs** and writes the sample file to it - this folder is automatically uploaded to the experiment run"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you're almost ready to run the experiment. To run the script, you must create a **ScriptRunConfig** that identifies the Python script file to be run in the experiment, and then run an experiment based on it.\n",
        "\n",
        "> **Note**: The ScriptRunConfig also determines the compute target and Python environment. In this case, the Python environment is defined to include some Conda and pip packages, but the compute target is omitted; so the default local compute will be used.\n",
        "\n",
        "The following cell configures and submits the script-based experiment."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
        "from azureml.core.runconfig import DockerConfiguration\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Create a Python environment for the experiment (from a .yml file)\n",
        "env = Environment.from_conda_specification(\"experiment_env\", \"environment.yml\")\n",
        "\n",
        "# Create a script config\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                                script='diabetes_experiment.py',\n",
        "                                environment=env,\n",
        "                                docker_runtime_config=DockerConfiguration(use_docker=True))\n",
        "\n",
        "# submit the experiment\n",
        "experiment = Experiment(workspace=ws, name='mslearn-diabetes')\n",
        "run = experiment.submit(config=script_config)\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e47c31b8b5bb4811b80552b8a5470b6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/mslearn-diabetes_1665910669_53b5ce9f?wsid=/subscriptions/fe87babe-9ce9-43f8-b0aa-70603823aca8/resourcegroups/exercise_train_a_deep_neural_network/workspaces/exercise_deep_neural_network&tid=d6755233-46af-4030-8906-057bd29a9ee8\", \"run_id\": \"mslearn-diabetes_1665910669_53b5ce9f\", \"run_properties\": {\"run_id\": \"mslearn-diabetes_1665910669_53b5ce9f\", \"created_utc\": \"2022-10-16T08:57:50.405159Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"0ea02dc3-3d76-4b32-8f7d-5563c2ca006b\"}, \"tags\": {\"mlflow.source.type\": \"JOB\", \"mlflow.source.name\": \"diabetes_experiment.py\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2022-10-16T09:02:05.281189Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://exercisedeepne4107602632.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes_1665910669_53b5ce9f/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=%2BuzXgiur%2F9wUTgBaEJJUYJZXKxNWM8qY8lDyCptp%2F%2FM%3D&skoid=f7312be2-3e76-4d30-b80f-d3839b51041e&sktid=d6755233-46af-4030-8906-057bd29a9ee8&skt=2022-10-16T08%3A47%3A10Z&ske=2022-10-17T16%3A57%3A10Z&sks=b&skv=2019-07-07&st=2022-10-16T08%3A52%3A06Z&se=2022-10-16T17%3A02%3A06Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://exercisedeepne4107602632.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes_1665910669_53b5ce9f/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=Y4oE%2FFF4jEv8Wt%2FMTg%2Bugw44%2F7sQcoJFJ56PqOh8q6w%3D&skoid=f7312be2-3e76-4d30-b80f-d3839b51041e&sktid=d6755233-46af-4030-8906-057bd29a9ee8&skt=2022-10-16T08%3A47%3A10Z&ske=2022-10-17T16%3A57%3A10Z&sks=b&skv=2019-07-07&st=2022-10-16T08%3A52%3A06Z&se=2022-10-16T17%3A02%3A06Z&sp=r\", \"logs/azureml/9_azureml.log\": \"https://exercisedeepne4107602632.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes_1665910669_53b5ce9f/logs/azureml/9_azureml.log?sv=2019-07-07&sr=b&sig=WwN9kws3%2BS0eEQZqQBDsL%2BtN25GN88CdKkVZT0Zx7v0%3D&skoid=f7312be2-3e76-4d30-b80f-d3839b51041e&sktid=d6755233-46af-4030-8906-057bd29a9ee8&skt=2022-10-16T08%3A47%3A10Z&ske=2022-10-17T16%3A57%3A10Z&sks=b&skv=2019-07-07&st=2022-10-16T08%3A57%3A06Z&se=2022-10-16T17%3A07%3A06Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/9_azureml.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"]], \"run_duration\": \"0:04:14\", \"run_number\": \"1665910670\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"observations\", \"run_id\": \"mslearn-diabetes_1665910669_53b5ce9f\", \"categories\": [0], \"series\": [{\"data\": [10000]}]}, {\"name\": \"Label:0\", \"run_id\": \"mslearn-diabetes_1665910669_53b5ce9f\", \"categories\": [0], \"series\": [{\"data\": [6656]}]}, {\"name\": \"Label:1\", \"run_id\": \"mslearn-diabetes_1665910669_53b5ce9f\", \"categories\": [0], \"series\": [{\"data\": [3344]}]}], \"run_logs\": \"[2022-10-16T09:01:54.505934] Entering context manager injector.\\nCannot provide tracer without any exporter configured.\\n/azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages/paramiko/transport.py:33: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.\\n  from cryptography.hazmat.backends import default_backend\\n[2022-10-16T09:01:55.387355] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['diabetes_experiment.py'])\\nScript type = None\\n[2022-10-16T09:01:55.390946] Entering Run History Context Manager.\\n/azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages/azureml/history/_tracking.py:367: FutureWarning: azureml.core: AzureML support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use AzureML will continue to work without modification, but Python 3.6 users will no longer get access to the latest AzureML features and bugfixes. We recommend that you upgrade to Python 3.7 or newer. To disable SDK V1 deprecation warning set the environment variable AZUREML_DEPRECATE_WARNING to 'False'\\n  from azureml.core.run import Run\\n/azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages/azureml/history/_tracking.py:186: FutureWarning: MLflow support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use MLflow will continue to work without modification, but Python 3.6 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3.7 or newer.\\n  import mlflow\\n[2022-10-16T09:01:57.523174] Current directory: /azureml-run\\n[2022-10-16T09:01:57.523208] Preparing to call script [diabetes_experiment.py] with arguments:[]\\n[2022-10-16T09:01:57.523225] After variable expansion, calling script [diabetes_experiment.py] with arguments:[]\\n\\nAnalyzing 10000 rows of data\\n0    6656\\n1    3344\\nName: Diabetic, dtype: int64\\n\\n\\n[2022-10-16T09:02:03.268311] The experiment completed successfully. Finalizing run...\\n[2022-10-16T09:02:03.268330] Start FinalizingInRunHistory\\n[2022-10-16T09:02:03.270025] Logging experiment finalizing status in history service.\\nStarting the daemon thread to refresh tokens in background for process with pid = 9\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\n2 items cleaning up...\\nCleanup took 0.08803200721740723 seconds\\n[2022-10-16T09:02:04.160972] Finished context manager injector.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.44.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "{'runId': 'mslearn-diabetes_1665910669_53b5ce9f',\n 'target': 'local',\n 'status': 'Completed',\n 'startTimeUtc': '2022-10-16T09:01:53.586804Z',\n 'endTimeUtc': '2022-10-16T09:02:05.281189Z',\n 'services': {},\n 'properties': {'_azureml.ComputeTargetType': 'local',\n  'ContentSnapshotId': '0ea02dc3-3d76-4b32-8f7d-5563c2ca006b'},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'runDefinition': {'script': 'diabetes_experiment.py',\n  'command': '',\n  'useAbsolutePath': False,\n  'arguments': [],\n  'sourceDirectoryDataStore': None,\n  'framework': 'Python',\n  'communicator': 'None',\n  'target': 'local',\n  'dataReferences': {},\n  'data': {},\n  'outputData': {},\n  'datacaches': [],\n  'jobName': None,\n  'maxRunDurationSeconds': 2592000,\n  'nodeCount': 1,\n  'instanceTypes': [],\n  'priority': None,\n  'credentialPassthrough': False,\n  'identity': None,\n  'environment': {'name': 'experiment_env',\n   'version': 'Autosave_2022-10-16T08:57:50Z_1ee1058a',\n   'assetId': 'azureml://locations/koreacentral/workspaces/485e4726-126f-4aa3-96ea-46e7eec8fc27/environments/experiment_env/versions/Autosave_2022-10-16T08:57:50Z_1ee1058a',\n   'autoRebuild': True,\n   'python': {'interpreterPath': 'python',\n    'userManagedDependencies': False,\n    'condaDependencies': {'dependencies': ['python=3.6.2',\n      'scikit-learn',\n      'pandas',\n      'pip',\n      {'pip': ['azureml-defaults', 'azureml-mlflow']}],\n     'name': 'simple_environment'},\n    'baseCondaEnvironment': None},\n   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1',\n    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n    'baseDockerfile': None,\n    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n    'enabled': False,\n    'arguments': []},\n   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n   'inferencingStackVersion': None},\n  'history': {'outputCollection': True,\n   'directoriesToWatch': ['logs'],\n   'enableMLflowTracking': True,\n   'snapshotProject': True},\n  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n    'spark.yarn.maxAppAttempts': '1'}},\n  'parallelTask': {'maxRetriesPerWorker': 0,\n   'workerCountPerNode': 1,\n   'terminalExitCodes': None,\n   'configuration': {}},\n  'amlCompute': {'name': None,\n   'vmSize': None,\n   'retainCluster': False,\n   'clusterMaxNodeCount': None},\n  'aiSuperComputer': {'instanceType': 'D2',\n   'imageVersion': 'pytorch-1.7.0',\n   'location': None,\n   'aiSuperComputerStorageData': None,\n   'interactive': False,\n   'scalePolicy': None,\n   'virtualClusterArmId': None,\n   'tensorboardLogDirectory': None,\n   'sshPublicKey': None,\n   'sshPublicKeys': None,\n   'enableAzmlInt': True,\n   'priority': 'Medium',\n   'slaTier': 'Standard',\n   'userAlias': None},\n  'kubernetesCompute': {'instanceType': None},\n  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n  'mpi': {'processCountPerNode': 1},\n  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n  'hdi': {'yarnDeployMode': 'Cluster'},\n  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n  'exposedPorts': None,\n  'docker': {'useDocker': True,\n   'sharedVolumes': True,\n   'shmSize': '2g',\n   'arguments': []},\n  'cmk8sCompute': {'configuration': {}},\n  'commandReturnCodeConfig': {'returnCode': 'Zero',\n   'successfulReturnCodes': []},\n  'environmentVariables': {},\n  'applicationEndpoints': {},\n  'parameters': []},\n 'logFiles': {'azureml-logs/60_control_log.txt': 'https://exercisedeepne4107602632.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes_1665910669_53b5ce9f/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=%2BuzXgiur%2F9wUTgBaEJJUYJZXKxNWM8qY8lDyCptp%2F%2FM%3D&skoid=f7312be2-3e76-4d30-b80f-d3839b51041e&sktid=d6755233-46af-4030-8906-057bd29a9ee8&skt=2022-10-16T08%3A47%3A10Z&ske=2022-10-17T16%3A57%3A10Z&sks=b&skv=2019-07-07&st=2022-10-16T08%3A52%3A06Z&se=2022-10-16T17%3A02%3A06Z&sp=r',\n  'azureml-logs/70_driver_log.txt': 'https://exercisedeepne4107602632.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes_1665910669_53b5ce9f/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=Y4oE%2FFF4jEv8Wt%2FMTg%2Bugw44%2F7sQcoJFJ56PqOh8q6w%3D&skoid=f7312be2-3e76-4d30-b80f-d3839b51041e&sktid=d6755233-46af-4030-8906-057bd29a9ee8&skt=2022-10-16T08%3A47%3A10Z&ske=2022-10-17T16%3A57%3A10Z&sks=b&skv=2019-07-07&st=2022-10-16T08%3A52%3A06Z&se=2022-10-16T17%3A02%3A06Z&sp=r',\n  'logs/azureml/9_azureml.log': 'https://exercisedeepne4107602632.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes_1665910669_53b5ce9f/logs/azureml/9_azureml.log?sv=2019-07-07&sr=b&sig=UIwC2EJZ%2FnUHU2hgFF1CafufMkNOsbdnymOUPZGXoYw%3D&skoid=f7312be2-3e76-4d30-b80f-d3839b51041e&sktid=d6755233-46af-4030-8906-057bd29a9ee8&skt=2022-10-16T08%3A47%3A10Z&ske=2022-10-17T16%3A57%3A10Z&sks=b&skv=2019-07-07&st=2022-10-16T08%3A52%3A01Z&se=2022-10-16T17%3A02%3A01Z&sp=r'},\n 'submittedBy': '형진 김'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1665910926636
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As before, you can use the widget or the link to the experiment in [Azure Machine Learning studio](https://ml.azure.com) to view the outputs generated by the experiment, and you can also write code to retrieve the metrics and files it generated:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get logged metrics\n",
        "metrics = run.get_metrics()\n",
        "for key in metrics.keys():\n",
        "        print(key, metrics.get(key))\n",
        "print('\\n')\n",
        "for file in run.get_file_names():\n",
        "    print(file)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "observations 10000\nLabel:0 6656\nLabel:1 3344\n\n\nazureml-logs/60_control_log.txt\nazureml-logs/70_driver_log.txt\nlogs/azureml/9_azureml.log\noutputs/sample.csv\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1665910926925
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that this time, the run generated some log files. You can view these in the widget, or you can use the **get_details_with_logs** method like we did before, only this time the output will include the log data."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "run.get_details_with_logs()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "{'runId': 'mslearn-diabetes_1665910669_53b5ce9f',\n 'target': 'local',\n 'status': 'Completed',\n 'startTimeUtc': '2022-10-16T09:01:53.586804Z',\n 'endTimeUtc': '2022-10-16T09:02:05.281189Z',\n 'services': {},\n 'properties': {'_azureml.ComputeTargetType': 'local',\n  'ContentSnapshotId': '0ea02dc3-3d76-4b32-8f7d-5563c2ca006b'},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'runDefinition': {'script': 'diabetes_experiment.py',\n  'command': '',\n  'useAbsolutePath': False,\n  'arguments': [],\n  'sourceDirectoryDataStore': None,\n  'framework': 'Python',\n  'communicator': 'None',\n  'target': 'local',\n  'dataReferences': {},\n  'data': {},\n  'outputData': {},\n  'datacaches': [],\n  'jobName': None,\n  'maxRunDurationSeconds': 2592000,\n  'nodeCount': 1,\n  'instanceTypes': [],\n  'priority': None,\n  'credentialPassthrough': False,\n  'identity': None,\n  'environment': {'name': 'experiment_env',\n   'version': 'Autosave_2022-10-16T08:57:50Z_1ee1058a',\n   'assetId': 'azureml://locations/koreacentral/workspaces/485e4726-126f-4aa3-96ea-46e7eec8fc27/environments/experiment_env/versions/Autosave_2022-10-16T08:57:50Z_1ee1058a',\n   'autoRebuild': True,\n   'python': {'interpreterPath': 'python',\n    'userManagedDependencies': False,\n    'condaDependencies': {'dependencies': ['python=3.6.2',\n      'scikit-learn',\n      'pandas',\n      'pip',\n      {'pip': ['azureml-defaults', 'azureml-mlflow']}],\n     'name': 'simple_environment'},\n    'baseCondaEnvironment': None},\n   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1',\n    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n    'baseDockerfile': None,\n    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n    'enabled': False,\n    'arguments': []},\n   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n   'inferencingStackVersion': None},\n  'history': {'outputCollection': True,\n   'directoriesToWatch': ['logs'],\n   'enableMLflowTracking': True,\n   'snapshotProject': True},\n  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n    'spark.yarn.maxAppAttempts': '1'}},\n  'parallelTask': {'maxRetriesPerWorker': 0,\n   'workerCountPerNode': 1,\n   'terminalExitCodes': None,\n   'configuration': {}},\n  'amlCompute': {'name': None,\n   'vmSize': None,\n   'retainCluster': False,\n   'clusterMaxNodeCount': None},\n  'aiSuperComputer': {'instanceType': 'D2',\n   'imageVersion': 'pytorch-1.7.0',\n   'location': None,\n   'aiSuperComputerStorageData': None,\n   'interactive': False,\n   'scalePolicy': None,\n   'virtualClusterArmId': None,\n   'tensorboardLogDirectory': None,\n   'sshPublicKey': None,\n   'sshPublicKeys': None,\n   'enableAzmlInt': True,\n   'priority': 'Medium',\n   'slaTier': 'Standard',\n   'userAlias': None},\n  'kubernetesCompute': {'instanceType': None},\n  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n  'mpi': {'processCountPerNode': 1},\n  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n  'hdi': {'yarnDeployMode': 'Cluster'},\n  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n  'exposedPorts': None,\n  'docker': {'useDocker': True,\n   'sharedVolumes': True,\n   'shmSize': '2g',\n   'arguments': []},\n  'cmk8sCompute': {'configuration': {}},\n  'commandReturnCodeConfig': {'returnCode': 'Zero',\n   'successfulReturnCodes': []},\n  'environmentVariables': {},\n  'applicationEndpoints': {},\n  'parameters': []},\n 'logFiles': {'azureml-logs/60_control_log.txt': '[2022-10-16T08:57:51.082340] Using urllib.request Python 3.0 or later\\nStreaming log file azureml-logs/60_control_log.txt\\nStarting the daemon thread to refresh tokens in background for process with pid = 10411\\nRunning: [\\'/bin/bash\\', \\'/tmp/azureml_runs/mslearn-diabetes_1665910669_53b5ce9f/azureml-environment-setup/docker_env_checker.sh\\']\\n\\nMaterialized image not found on target: azureml/azureml_ebb14aaae0caf88689036382aa234cf7\\n\\n\\n[2022-10-16T08:57:53.641719] Logging experiment preparation status in history service.\\nRunning: [\\'/bin/bash\\', \\'/tmp/azureml_runs/mslearn-diabetes_1665910669_53b5ce9f/azureml-environment-setup/docker_env_builder.sh\\']\\nRunning: [\\'nvidia-docker\\', \\'build\\', \\'-f\\', \\'azureml-environment-setup/Dockerfile\\', \\'-t\\', \\'azureml/azureml_ebb14aaae0caf88689036382aa234cf7\\', \\'.\\']\\nSending build context to Docker daemon   1.12MB\\nStep 1/17 : FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1@sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6\\nmcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1@sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6: Pulling from azureml/openmpi4.1.0-ubuntu20.04\\nd7bfe07ed847: Pulling fs layer\\n1a9a51b4af0d: Pulling fs layer\\n9d74d44c539e: Pulling fs layer\\n829bf1798a9e: Pulling fs layer\\n5fe57cb5a06b: Pulling fs layer\\n0b73c9d3e4c7: Pulling fs layer\\ndf3a1ae83fc1: Pulling fs layer\\n622a938b5eec: Pulling fs layer\\n9d0e20c4f643: Pulling fs layer\\ne63d29d12ed0: Pulling fs layer\\n829bf1798a9e: Waiting\\n5fe57cb5a06b: Waiting\\n0b73c9d3e4c7: Waiting\\ndf3a1ae83fc1: Waiting\\n622a938b5eec: Waiting\\n9d0e20c4f643: Waiting\\ne63d29d12ed0: Waiting\\nd7bfe07ed847: Verifying Checksum\\nd7bfe07ed847: Download complete\\n829bf1798a9e: Verifying Checksum\\n829bf1798a9e: Download complete\\n5fe57cb5a06b: Verifying Checksum\\n5fe57cb5a06b: Download complete\\nd7bfe07ed847: Pull complete\\n0b73c9d3e4c7: Verifying Checksum\\n0b73c9d3e4c7: Download complete\\ndf3a1ae83fc1: Verifying Checksum\\ndf3a1ae83fc1: Download complete\\n9d74d44c539e: Verifying Checksum\\n9d74d44c539e: Download complete\\n9d0e20c4f643: Verifying Checksum\\n9d0e20c4f643: Download complete\\n622a938b5eec: Verifying Checksum\\n622a938b5eec: Download complete\\ne63d29d12ed0: Download complete\\n1a9a51b4af0d: Verifying Checksum\\n1a9a51b4af0d: Download complete\\n1a9a51b4af0d: Pull complete\\n9d74d44c539e: Pull complete\\n829bf1798a9e: Pull complete\\n5fe57cb5a06b: Pull complete\\n0b73c9d3e4c7: Pull complete\\ndf3a1ae83fc1: Pull complete\\n622a938b5eec: Pull complete\\n9d0e20c4f643: Pull complete\\ne63d29d12ed0: Pull complete\\nDigest: sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6\\nStatus: Downloaded newer image for mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1@sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6\\n ---> a126cf3d80b0\\nStep 2/17 : USER root\\n ---> Running in 6e8964085368\\nRemoving intermediate container 6e8964085368\\n ---> 53d532c8256e\\nStep 3/17 : RUN mkdir -p $HOME/.cache\\n ---> Running in 9f816270384f\\nRemoving intermediate container 9f816270384f\\n ---> 0b04a6491617\\nStep 4/17 : WORKDIR /\\n ---> Running in 2ed5b8ce127d\\nRemoving intermediate container 2ed5b8ce127d\\n ---> 7ac2e4c9a1e8\\nStep 5/17 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\\n ---> 3fd91e1ba4bd\\nStep 6/17 : RUN if dpkg --compare-versions `conda --version | grep -oE \\'[^ ]+$\\'` lt 4.4.11; then conda install conda==4.4.11; fi\\n ---> Running in 5bcaa52b5e44\\nRemoving intermediate container 5bcaa52b5e44\\n ---> bce8c2e22153\\nStep 7/17 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\\n ---> b716e30eaca2\\nStep 8/17 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\\n ---> Running in adf50b5bc7dd\\nCollecting package metadata (repodata.json): ...working... done\\nSolving environment: ...working... done\\n\\nDownloading and Extracting Packages\\npytz-2021.3          | 171 KB    | ########## | 100% \\nlibgomp-11.2.0       | 474 KB    | ########## | 100% \\nzlib-1.2.12          | 103 KB    | ########## | 100% \\npython-3.6.2         | 23.6 MB   | ########## | 100% \\nnumpy-1.19.2         | 22 KB     | ########## | 100% \\nlibgfortran4-7.5.0   | 995 KB    | ########## | 100% \\nblas-1.0             | 6 KB      | ########## | 100% \\nlibstdcxx-ng-11.2.0  | 4.7 MB    | ########## | 100% \\nlibffi-3.2.1         | 48 KB     | ########## | 100% \\nmkl-service-2.3.0    | 52 KB     | ########## | 100% \\nncurses-6.0          | 781 KB    | ########## | 100% \\nsqlite-3.23.1        | 808 KB    | ########## | 100% \\nscikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \\nopenssl-1.0.2u       | 2.2 MB    | ########## | 100% \\npip-21.2.2           | 1.8 MB    | ########## | 100% \\nintel-openmp-2022.1. | 4.5 MB    | ########## | 100% \\nmkl_fft-1.3.0        | 170 KB    | ########## | 100% \\npandas-1.1.5         | 8.2 MB    | ########## | 100% \\nscipy-1.5.2          | 14.4 MB   | ########## | 100% \\nnumpy-base-1.19.2    | 4.1 MB    | ########## | 100% \\nlibgcc-ng-11.2.0     | 5.3 MB    | ########## | 100% \\nmkl-2020.2           | 138.3 MB  | ########## | 100% \\ntk-8.6.12            | 3.0 MB    | ########## | 100% \\nxz-5.2.6             | 394 KB    | ########## | 100% \\nlibgfortran-ng-7.5.0 | 22 KB     | ########## | 100% \\n_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \\n_openmp_mutex-5.1    | 21 KB     | ########## | 100% \\nlibedit-3.1          | 151 KB    | ########## | 100% \\nreadline-7.0         | 848 KB    | ########## | 100% \\nsix-1.16.0           | 18 KB     | ########## | 100% \\nthreadpoolctl-2.2.0  | 16 KB     | ########## | 100% \\ncertifi-2021.5.30    | 139 KB    | ########## | 100% \\npython-dateutil-2.8. | 233 KB    | ########## | 100% \\nmkl_random-1.1.1     | 327 KB    | ########## | 100% \\nsetuptools-58.0.4    | 788 KB    | ########## | 100% \\nwheel-0.37.1         | 33 KB     | ########## | 100% \\njoblib-1.0.1         | 208 KB    | ########## | 100% \\nca-certificates-2022 | 124 KB    | ########## | 100% \\nPreparing transaction: ...working... done\\nVerifying transaction: ...working... done\\nExecuting transaction: ...working... \\n\\n    Installed package of scikit-learn can be accelerated using scikit-learn-intelex.\\n    More details are available here: https://intel.github.io/scikit-learn-intelex\\n\\n    For example:\\n\\n        $ conda install scikit-learn-intelex\\n        $ python -m sklearnex my_application.py\\n\\n    \\n\\ndone\\nInstalling pip dependencies: ...working... Ran pip subprocess with arguments:\\n[\\'/azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/bin/python\\', \\'-m\\', \\'pip\\', \\'install\\', \\'-U\\', \\'-r\\', \\'/azureml-environment-setup/condaenv.ylr0e6rs.requirements.txt\\']\\nPip subprocess output:\\nCollecting azureml-defaults\\n  Downloading azureml_defaults-1.46.0-py3-none-any.whl (2.0 kB)\\nCollecting azureml-mlflow\\n  Downloading azureml_mlflow-1.46.0-py3-none-any.whl (811 kB)\\nCollecting configparser==3.7.4\\n  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\\nCollecting azureml-dataset-runtime[fuse]~=1.46.0\\n  Downloading azureml_dataset_runtime-1.46.0-py3-none-any.whl (2.3 kB)\\nCollecting json-logging-py==0.2\\n  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\\nCollecting azureml-inference-server-http~=0.7.2\\n  Downloading azureml_inference_server_http-0.7.6-py3-none-any.whl (56 kB)\\nCollecting azureml-core~=1.46.0\\n  Downloading azureml_core-1.46.0-py3-none-any.whl (3.1 MB)\\nCollecting azure-mgmt-core<2.0.0,>=1.2.0\\n  Downloading azure_mgmt_core-1.3.2-py3-none-any.whl (26 kB)\\nCollecting azure-core!=1.22.0,<2.0.0,>=1.8.0\\n  Downloading azure_core-1.24.2-py3-none-any.whl (178 kB)\\nCollecting cryptography\\n  Downloading cryptography-38.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\\nCollecting azure-identity\\n  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)\\nCollecting jsonpickle\\n  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\\nRequirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages (from azureml-mlflow->-r /azureml-environment-setup/condaenv.ylr0e6rs.requirements.txt (line 2)) (2.8.2)\\nCollecting mlflow-skinny\\n  Downloading mlflow_skinny-1.23.1-py3-none-any.whl (3.2 MB)\\nCollecting azure-storage-blob<=12.13.0,>=12.5.0\\n  Downloading azure_storage_blob-12.13.0-py3-none-any.whl (377 kB)\\nCollecting msrest>=0.6.18\\n  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\\nCollecting azure-common<2.0.0,>=1.1\\n  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\\nRequirement already satisfied: six>=1.11.0 in /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages (from azure-core!=1.22.0,<2.0.0,>=1.8.0->azureml-mlflow->-r /azureml-environment-setup/condaenv.ylr0e6rs.requirements.txt (line 2)) (1.16.0)\\nCollecting typing-extensions>=4.0.1\\n  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\\nCollecting requests>=2.18.4\\n  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\\nCollecting msrestazure<=0.6.4,>=0.4.33\\n  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\\nCollecting cryptography\\n  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\\nCollecting knack~=0.9.0\\n  Downloading knack-0.9.0-py3-none-any.whl (59 kB)\\nCollecting ndg-httpsclient<=0.5.1\\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\\nCollecting azure-graphrbac<1.0.0,>=0.40.0\\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\\nCollecting backports.tempfile\\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\\nCollecting argcomplete<3\\n  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\\nCollecting azure-mgmt-storage<=20.0.0,>=16.0.0\\n  Downloading azure_mgmt_storage-20.0.0-py3-none-any.whl (2.0 MB)\\nCollecting contextlib2<22.0.0\\n  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\\nCollecting pyopenssl<23.0.0\\n  Downloading pyOpenSSL-22.1.0-py3-none-any.whl (57 kB)\\nCollecting pathspec<1.0.0\\n  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\\nRequirement already satisfied: pytz in /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages (from azureml-core~=1.46.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ylr0e6rs.requirements.txt (line 1)) (2021.3)\\nCollecting docker<6.0.0\\n  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\\nCollecting azure-mgmt-resource<22.0.0,>=15.0.0\\n  Downloading azure_mgmt_resource-21.1.0-py3-none-any.whl (1.8 MB)\\nCollecting humanfriendly<11.0,>=4.7\\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\\nCollecting pkginfo\\n  Downloading pkginfo-1.8.3-py2.py3-none-any.whl (26 kB)\\nCollecting adal<=1.2.7,>=1.2.0\\n  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\\nCollecting azure-mgmt-containerregistry<11,>=8.2.0\\n  Downloading azure_mgmt_containerregistry-10.0.0-py3-none-any.whl (1.2 MB)\\nCollecting jmespath<2.0.0\\n  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\\nCollecting azure-mgmt-authorization<3,>=0.40.0\\n  Downloading azure_mgmt_authorization-2.0.0-py2.py3-none-any.whl (465 kB)\\nCollecting azure-mgmt-keyvault<11.0.0,>=0.40.0\\n  Downloading azure_mgmt_keyvault-10.0.0-py3-none-any.whl (489 kB)\\nCollecting packaging<22.0,>=20.0\\n  Downloading packaging-21.3-py3-none-any.whl (40 kB)\\nCollecting paramiko<3.0.0,>=2.0.8\\n  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\\nCollecting SecretStorage<4.0.0\\n  Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\\nCollecting urllib3<2.0.0,>=1.23\\n  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\\nCollecting PyJWT<3.0.0\\n  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\\nCollecting msal<2.0.0,>=1.15.0\\n  Downloading msal-1.20.0-py2.py3-none-any.whl (90 kB)\\nCollecting msal-extensions<=1.0.0,>=0.3.0\\n  Downloading msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\\nCollecting importlib-metadata<5,>=0.23\\n  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\\nCollecting azureml-dataprep<4.6.0a,>=4.5.0a\\n  Downloading azureml_dataprep-4.5.7-py3-none-any.whl (43.4 MB)\\nRequirement already satisfied: numpy!=1.19.3 in /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages (from azureml-dataset-runtime[fuse]~=1.46.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ylr0e6rs.requirements.txt (line 1)) (1.19.2)\\nCollecting pyarrow<=9.0.0,>=0.17.0\\n  Downloading pyarrow-6.0.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\\nCollecting fusepy<4.0.0,>=3.0.1\\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\\nCollecting cloudpickle<3.0.0,>=1.1.0\\n  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\\nCollecting dotnetcore2<4.0.0,>=3.0.0\\n  Downloading dotnetcore2-3.1.23-py3-none-manylinux1_x86_64.whl (31.1 MB)\\nCollecting azure-identity\\n  Downloading azure_identity-1.7.0-py2.py3-none-any.whl (129 kB)\\nCollecting pyyaml<7.0.0,>=5.1.0\\n  Downloading PyYAML-6.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (603 kB)\\nCollecting azureml-dataprep-rslex~=2.11.0dev0\\n  Downloading azureml_dataprep_rslex-2.11.4-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.3 MB)\\nCollecting jsonschema\\n  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\\nCollecting azureml-dataprep-native<39.0.0,>=38.0.0\\n  Downloading azureml_dataprep_native-38.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\\nCollecting msal-extensions<=1.0.0,>=0.3.0\\n  Downloading msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\\nCollecting flask-cors~=3.0.1\\n  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\\nCollecting gunicorn==20.1.0\\n  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\\nCollecting flask<2.2.0\\n  Downloading Flask-2.0.3-py3-none-any.whl (95 kB)\\nCollecting opencensus-ext-azure~=1.1.0\\n  Downloading opencensus_ext_azure-1.1.7-py2.py3-none-any.whl (42 kB)\\nCollecting inference-schema~=1.4.0\\n  Downloading inference_schema-1.4.2.1-py3-none-any.whl (21 kB)\\nRequirement already satisfied: setuptools>=3.0 in /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages (from gunicorn==20.1.0->azureml-inference-server-http~=0.7.2->azureml-defaults->-r /azureml-environment-setup/condaenv.ylr0e6rs.requirements.txt (line 1)) (58.0.4)\\nCollecting cffi>=1.12\\n  Downloading cffi-1.15.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (402 kB)\\nCollecting pycparser\\n  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\\nCollecting websocket-client>=0.32.0\\n  Downloading websocket_client-1.3.1-py3-none-any.whl (54 kB)\\nCollecting distro>=1.2.0\\n  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\\nCollecting Werkzeug>=2.0\\n  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\\nCollecting itsdangerous>=2.0\\n  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\\nCollecting click>=7.1.2\\n  Downloading click-8.0.4-py3-none-any.whl (97 kB)\\nCollecting Jinja2>=3.0\\n  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\\nCollecting zipp>=0.5\\n  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\\nCollecting wrapt<=1.12.1,>=1.11.1\\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\\nCollecting MarkupSafe>=2.0\\n  Downloading MarkupSafe-2.0.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)\\nCollecting pygments\\n  Downloading Pygments-2.13.0-py3-none-any.whl (1.1 MB)\\nCollecting tabulate\\n  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\\nCollecting portalocker<3,>=1.0\\n  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\\nRequirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages (from msrest>=0.6.18->azureml-mlflow->-r /azureml-environment-setup/condaenv.ylr0e6rs.requirements.txt (line 2)) (2021.5.30)\\nCollecting requests-oauthlib>=0.5.0\\n  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\\nCollecting isodate>=0.6.0\\n  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\\nCollecting pyasn1>=0.1.1\\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\\nCollecting opencensus<1.0.0,>=0.11.0\\n  Downloading opencensus-0.11.0-py2.py3-none-any.whl (128 kB)\\nCollecting psutil>=5.6.3\\n  Downloading psutil-5.9.2-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\\nCollecting google-api-core<3.0.0,>=1.0.0\\n  Downloading google_api_core-2.8.2-py3-none-any.whl (114 kB)\\nCollecting opencensus-context>=0.1.3\\n  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\\nCollecting protobuf<5.0.0dev,>=3.15.0\\n  Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\\nCollecting google-auth<3.0dev,>=1.25.0\\n  Downloading google_auth-2.12.0-py2.py3-none-any.whl (169 kB)\\nCollecting googleapis-common-protos<2.0dev,>=1.56.2\\n  Downloading googleapis_common_protos-1.56.3-py2.py3-none-any.whl (211 kB)\\nCollecting rsa<5,>=3.1.4\\n  Downloading rsa-4.9-py3-none-any.whl (34 kB)\\nCollecting cachetools<6.0,>=2.0.0\\n  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\\nCollecting pyasn1-modules>=0.2.1\\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\\nCollecting contextvars\\n  Downloading contextvars-2.4.tar.gz (9.6 kB)\\nCollecting pyparsing!=3.0.5,>=2.0.2\\n  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\\nCollecting bcrypt>=3.1.3\\n  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\\nCollecting pynacl>=1.0.1\\n  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\\nCollecting pyopenssl<23.0.0\\n  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\\nCollecting idna<4,>=2.5\\n  Downloading idna-3.4-py3-none-any.whl (61 kB)\\nCollecting charset-normalizer~=2.0.0\\n  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\\nCollecting oauthlib>=3.0.0\\n  Downloading oauthlib-3.2.1-py3-none-any.whl (151 kB)\\nCollecting PySocks!=1.5.7,>=1.5.6\\n  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\\nCollecting jeepney>=0.6\\n  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\\nCollecting dataclasses\\n  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\\nCollecting backports.weakref\\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\\nCollecting immutables>=0.9\\n  Downloading immutables-0.19-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (116 kB)\\nCollecting attrs>=17.4.0\\n  Downloading attrs-22.1.0-py2.py3-none-any.whl (58 kB)\\nCollecting pyrsistent>=0.14.0\\n  Downloading pyrsistent-0.18.0-cp36-cp36m-manylinux1_x86_64.whl (117 kB)\\nCollecting databricks-cli>=0.8.7\\n  Downloading databricks-cli-0.17.3.tar.gz (77 kB)\\nCollecting gitpython>=2.1.0\\n  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\\nCollecting entrypoints\\n  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\\nCollecting gitdb<5,>=4.0.1\\n  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\\nCollecting smmap<6,>=3.0.1\\n  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\\nBuilding wheels for collected packages: json-logging-py, fusepy, wrapt, contextvars, databricks-cli\\n  Building wheel for json-logging-py (setup.py): started\\n  Building wheel for json-logging-py (setup.py): finished with status \\'done\\'\\n  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=c9b548f5d0ebfcf3e7e4e2ec10e2a58170650201761e16997627a08d14b909fa\\n  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\\n  Building wheel for fusepy (setup.py): started\\n  Building wheel for fusepy (setup.py): finished with status \\'done\\'\\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=b5f77118fcbbd58f05559d8de650a4d51e81f2e919419695d485bca8d102ca28\\n  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\\n  Building wheel for wrapt (setup.py): started\\n  Building wheel for wrapt (setup.py): finished with status \\'done\\'\\n  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=76174 sha256=c9cd128cf9656da4615e8e029a5706967dd736cf7868e78103b5c809453383e1\\n  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\\n  Building wheel for contextvars (setup.py): started\\n  Building wheel for contextvars (setup.py): finished with status \\'done\\'\\n  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7681 sha256=f1a5a9d89348c5cc82f5a18423c8156408906770a683569ffeee8e730cffbd42\\n  Stored in directory: /root/.cache/pip/wheels/41/11/53/911724983aa48deb94792432e14e518447212dd6c5477d49d3\\n  Building wheel for databricks-cli (setup.py): started\\n  Building wheel for databricks-cli (setup.py): finished with status \\'done\\'\\n  Created wheel for databricks-cli: filename=databricks_cli-0.17.3-py3-none-any.whl size=139102 sha256=8cba5879c0f0cf2fe8b6f7455893acb3700bac2062cfec5c277abe0a47ae344e\\n  Stored in directory: /root/.cache/pip/wheels/58/04/45/0f84000ef6c124a8abcdf9924a4aeb30939680b09dcb4c56d3\\nSuccessfully built json-logging-py fusepy wrapt contextvars databricks-cli\\nInstalling collected packages: pycparser, cffi, urllib3, PyJWT, idna, cryptography, charset-normalizer, typing-extensions, requests, pyasn1, zipp, rsa, pyasn1-modules, protobuf, portalocker, oauthlib, msal, immutables, cachetools, requests-oauthlib, pyrsistent, msal-extensions, MarkupSafe, isodate, importlib-metadata, googleapis-common-protos, google-auth, distro, dataclasses, contextvars, azure-core, attrs, Werkzeug, smmap, pyyaml, opencensus-context, msrest, jsonschema, Jinja2, itsdangerous, google-api-core, dotnetcore2, cloudpickle, click, azureml-dataprep-rslex, azureml-dataprep-native, azure-identity, adal, wrapt, websocket-client, tabulate, PySocks, pyparsing, pyopenssl, pynacl, pygments, pyarrow, psutil, opencensus, msrestazure, jmespath, jeepney, gitdb, flask, bcrypt, backports.weakref, azureml-dataprep, azure-mgmt-core, azure-common, argcomplete, SecretStorage, pkginfo, pathspec, paramiko, packaging, opencensus-ext-azure, ndg-httpsclient, knack, jsonpickle, inference-schema, humanfriendly, gunicorn, gitpython, fusepy, flask-cors, entrypoints, docker, databricks-cli, contextlib2, backports.tempfile, azureml-dataset-runtime, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-graphrbac, mlflow-skinny, json-logging-py, configparser, azureml-inference-server-http, azureml-core, azure-storage-blob, azureml-mlflow, azureml-defaults\\nSuccessfully installed Jinja2-3.0.3 MarkupSafe-2.0.1 PyJWT-2.4.0 PySocks-1.7.1 SecretStorage-3.3.3 Werkzeug-2.0.3 adal-1.2.7 argcomplete-2.0.0 attrs-22.1.0 azure-common-1.1.28 azure-core-1.24.2 azure-graphrbac-0.61.1 azure-identity-1.7.0 azure-mgmt-authorization-2.0.0 azure-mgmt-containerregistry-10.0.0 azure-mgmt-core-1.3.2 azure-mgmt-keyvault-10.0.0 azure-mgmt-resource-21.1.0 azure-mgmt-storage-20.0.0 azure-storage-blob-12.13.0 azureml-core-1.46.0 azureml-dataprep-4.5.7 azureml-dataprep-native-38.0.0 azureml-dataprep-rslex-2.11.4 azureml-dataset-runtime-1.46.0 azureml-defaults-1.46.0 azureml-inference-server-http-0.7.6 azureml-mlflow-1.46.0 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-4.0.1 cachetools-4.2.4 cffi-1.15.1 charset-normalizer-2.0.12 click-8.0.4 cloudpickle-2.2.0 configparser-3.7.4 contextlib2-21.6.0 contextvars-2.4 cryptography-37.0.4 databricks-cli-0.17.3 dataclasses-0.8 distro-1.8.0 docker-5.0.3 dotnetcore2-3.1.23 entrypoints-0.4 flask-2.0.3 flask-cors-3.0.10 fusepy-3.0.1 gitdb-4.0.9 gitpython-3.1.18 google-api-core-2.8.2 google-auth-2.12.0 googleapis-common-protos-1.56.3 gunicorn-20.1.0 humanfriendly-10.0 idna-3.4 immutables-0.19 importlib-metadata-4.8.3 inference-schema-1.4.2.1 isodate-0.6.1 itsdangerous-2.0.1 jeepney-0.7.1 jmespath-0.10.0 json-logging-py-0.2 jsonpickle-2.2.0 jsonschema-3.2.0 knack-0.9.0 mlflow-skinny-1.23.1 msal-1.20.0 msal-extensions-0.3.1 msrest-0.7.1 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.2.1 opencensus-0.11.0 opencensus-context-0.1.3 opencensus-ext-azure-1.1.7 packaging-21.3 paramiko-2.11.0 pathspec-0.9.0 pkginfo-1.8.3 portalocker-2.5.1 protobuf-3.19.6 psutil-5.9.2 pyarrow-6.0.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.21 pygments-2.13.0 pynacl-1.5.0 pyopenssl-22.0.0 pyparsing-3.0.7 pyrsistent-0.18.0 pyyaml-6.0 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.9 smmap-5.0.0 tabulate-0.8.10 typing-extensions-4.1.1 urllib3-1.26.12 websocket-client-1.3.1 wrapt-1.12.1 zipp-3.6.0\\n\\ndone\\n\\x1b[91m\\n\\n==> WARNING: A newer version of conda exists. <==\\n  current version: 4.11.0\\n  latest version: 22.9.0\\n\\nPlease update conda by running\\n\\n    $ conda update -n base -c defaults conda\\n\\n\\n\\x1b[0m#\\n# To activate this environment, use\\n#\\n#     $ conda activate /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61\\n#\\n# To deactivate an active environment, use\\n#\\n#     $ conda deactivate\\n\\nWARNING: /root/.conda/pkgs does not exist\\nRemoving intermediate container adf50b5bc7dd\\n ---> f6344fa8423b\\nStep 9/17 : ENV PATH /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/bin:$PATH\\n ---> Running in 9e23a9f41022\\nRemoving intermediate container 9e23a9f41022\\n ---> 3e63362b6926\\nStep 10/17 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61\\n ---> Running in 5fa85321289f\\nRemoving intermediate container 5fa85321289f\\n ---> a876247d0158\\nStep 11/17 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib:$LD_LIBRARY_PATH\\n ---> Running in bf96ff239011\\nRemoving intermediate container bf96ff239011\\n ---> 8c33c0dac6c9\\nStep 12/17 : ENV CONDA_DEFAULT_ENV=azureml_809a074975457de1dd27bdfcf2d79d61 CONDA_PREFIX=/azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61\\n ---> Running in 4d754cb8ba5f\\nRemoving intermediate container 4d754cb8ba5f\\n ---> 139a4321e445\\nStep 13/17 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\\n ---> acf177d9830f\\nStep 14/17 : RUN if [ $SPARK_HOME ]; then /bin/bash -c \\'$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py\\'; fi\\n ---> Running in 09b22ea86bf2\\nRemoving intermediate container 09b22ea86bf2\\n ---> 2ec32d790902\\nStep 15/17 : RUN rm -rf azureml-environment-setup\\n ---> Running in c1ae96181f58\\nRemoving intermediate container c1ae96181f58\\n ---> 8cb64cfb3a71\\nStep 16/17 : ENV AZUREML_ENVIRONMENT_IMAGE True\\n ---> Running in 00d63a5b4a9a\\nRemoving intermediate container 00d63a5b4a9a\\n ---> eba6b6694610\\nStep 17/17 : CMD [\"bash\"]\\n ---> Running in e5e4e6fc8fbb\\nRemoving intermediate container e5e4e6fc8fbb\\n ---> 329c96bb40aa\\nSuccessfully built 329c96bb40aa\\nSuccessfully tagged azureml/azureml_ebb14aaae0caf88689036382aa234cf7:latest\\n\\n\\n\\n\\n[2022-10-16T09:01:53.586742] Logging experiment running status in history service.\\nRunning: [\\'docker\\', \\'run\\', \\'--name\\', \\'mslearn-diabetes_1665910669_53b5ce9f\\', \\'--rm\\', \\'-v\\', \\'/tmp/azureml_runs/mslearn-diabetes_1665910669_53b5ce9f:/azureml-run\\', \\'--shm-size\\', \\'2g\\', \\'-e\\', \\'AZUREML_LOCALRUN=true\\', \\'-e\\', \\'AZUREML_CURRENT_CLOUD_METADATA={\"Portal\":\"https://portal.azure.com\",\"Authentication\":{\"AzureDataLakeStoreFileSystem\":null,\"SqlServerHostname\":null,\"AzureDataLakeAnalyticsCatalogAndJob\":null,\"KeyVaultDns\":null,\"Storage\":null,\"AzureFrontDoorEndpointSuffix\":null},\"Media\":\"https://rest.media.azure.net\",\"GraphAudience\":\"https://graph.windows.net/\",\"Graph\":\"https://graph.windows.net/\",\"Name\":\"AzureCloud\",\"Suffixes\":{\"LoginEndpoint\":null,\"Audiences\":null,\"Tenant\":null,\"IdentityProvider\":null},\"Batch\":\"https://batch.core.windows.net/\",\"ResourceManager\":\"https://management.azure.com/\",\"VmImageAliasDoc\":\"https://raw.githubusercontent.com/Azure/azure-rest-api-specs/master/arm-compute/quickstart-templates/aliases.json\",\"ActiveDirectoryDataLake\":\"https://datalake.azure.net/\",\"SqlManagement\":\"https://management.core.windows.net:8443/\",\"Gallery\":\"https://gallery.azure.com/\"}\\', \\'-e\\', \\'AZUREML_CURRENT_CLOUD=AzureCloud\\', \\'-e\\', \\'MLFLOW_TRACKING_TOKEN=eyJhbGciOiJSUzI1NiIsImtpZCI6IjQzMUMzNzE3RjVGN0Y1MDlCNzc4RTU5RjUyMTc0MkE4MjI2NjkxMTciLCJ0eXAiOiJKV1QifQ.eyJyb2xlIjoiQ29udHJpYnV0b3IiLCJzY29wZSI6Ii9zdWJzY3JpcHRpb25zL2ZlODdiYWJlLTljZTktNDNmOC1iMGFhLTcwNjAzODIzYWNhOC9yZXNvdXJjZUdyb3Vwcy9leGVyY2lzZV90cmFpbl9hX2RlZXBfbmV1cmFsX25ldHdvcmsvcHJvdmlkZXJzL01pY3Jvc29mdC5NYWNoaW5lTGVhcm5pbmdTZXJ2aWNlcy93b3Jrc3BhY2VzL2V4ZXJjaXNlX2RlZXBfbmV1cmFsX25ldHdvcmsiLCJhY2NvdW50aWQiOiIwMDAwMDAwMC0wMDAwLTAwMDAtMDAwMC0wMDAwMDAwMDAwMDAiLCJ3b3Jrc3BhY2VJZCI6IjQ4NWU0NzI2LTEyNmYtNGFhMy05NmVhLTQ2ZTdlZWM4ZmMyNyIsInByb2plY3RpZCI6IjAwMDAwMDAwLTAwMDAtMDAwMC0wMDAwLTAwMDAwMDAwMDAwMCIsImRpc2NvdmVyeSI6InVyaTovL2Rpc2NvdmVyeXVyaS8iLCJ0aWQiOiJkNjc1NTIzMy00NmFmLTQwMzAtODkwNi0wNTdiZDI5YTllZTgiLCJvaWQiOiI5MTdlOTk2Yi0yNmU3LTQ3NWEtOTMyNC0xNWEzNWQ1OTBkYTAiLCJwdWlkIjoiMTAwMzIwMDIwMDlFODhFRCIsImlzcyI6ImF6dXJlbWwiLCJhcHBpZCI6Iu2YleynhCDquYAiLCJleHAiOjE2Njc3MzIyMjQsImF1ZCI6ImF6dXJlbWwifQ.WFfMj0FOYB_ejXjtZSW_9su5nJzs66IXbpjQn2h_XF8XLvJTvfdUhcYV1a-oqosPvOMrpR9aon0KQHyki1KNFRQdgxBmfX8fiPTNs6HmuNN7cU1crp_kduyu4zi_e3x1XJl07mozjIZDOF1X5j9U-gGAThWDWpUBhv-2m7dDoE-XMbEstXvEbBKV65QznAUm8fL3N-s7fhFEAe1USY1jePrvH3RCSrUMU8zd393bnVJ5oadFrpTrzaWrJBdfxgWRhbyQEKCJAM4YlXFkKpLGBV7YoWNUqHBFlwYPYIPEdj0UW9x-5AcuhP2tSqg7LfDJAy2w0Mw8NAwn6hwLEJhh1A\\', \\'-e\\', \\'MLFLOW_TRACKING_URI=azureml://koreacentral.api.azureml.ms/mlflow/v1.0/subscriptions/fe87babe-9ce9-43f8-b0aa-70603823aca8/resourceGroups/exercise_train_a_deep_neural_network/providers/Microsoft.MachineLearningServices/workspaces/exercise_deep_neural_network\\', \\'-e\\', \\'MLFLOW_RUN_ID=mslearn-diabetes_1665910669_53b5ce9f\\', \\'-e\\', \\'MLFLOW_EXPERIMENT_NAME=mslearn-diabetes\\', \\'-e\\', \\'MLFLOW_EXPERIMENT_ID=9fa555db-d343-4e0b-9e62-5e8a7fe8c939\\', \\'-e\\', \\'EXAMPLE_ENV_VAR=EXAMPLE_VALUE\\', \\'-e\\', \\'AZUREML_CONTEXT_MANAGER_TRACKUSERERROR=eyJTa2lwSGlzdG9yeUltcG9ydENoZWNrIjoiRmFsc2UifQ==\\', \\'-e\\', \\'AZUREML_CONTEXT_MANAGER_RUNHISTORY=eyJPdXRwdXRDb2xsZWN0aW9uIjp0cnVlLCJEaXJlY3Rvcmllc1RvV2F0Y2giOlsibG9ncyJdLCJFbmFibGVNTGZsb3dUcmFja2luZyI6dHJ1ZSwic25hcHNob3RQcm9qZWN0Ijp0cnVlfQ==\\', \\'-e\\', \\'AZUREML_CONTEXT_MANAGER_PROJECTPYTHONPATH=bnVsbA==\\', \\'-e\\', \\'AZUREML_RUN_TOKEN_EXPIRY=1667732224\\', \\'-e\\', \\'AZUREML_RUN_TOKEN=eyJhbGciOiJSUzI1NiIsImtpZCI6IjQzMUMzNzE3RjVGN0Y1MDlCNzc4RTU5RjUyMTc0MkE4MjI2NjkxMTciLCJ0eXAiOiJKV1QifQ.eyJyb2xlIjoiQ29udHJpYnV0b3IiLCJzY29wZSI6Ii9zdWJzY3JpcHRpb25zL2ZlODdiYWJlLTljZTktNDNmOC1iMGFhLTcwNjAzODIzYWNhOC9yZXNvdXJjZUdyb3Vwcy9leGVyY2lzZV90cmFpbl9hX2RlZXBfbmV1cmFsX25ldHdvcmsvcHJvdmlkZXJzL01pY3Jvc29mdC5NYWNoaW5lTGVhcm5pbmdTZXJ2aWNlcy93b3Jrc3BhY2VzL2V4ZXJjaXNlX2RlZXBfbmV1cmFsX25ldHdvcmsiLCJhY2NvdW50aWQiOiIwMDAwMDAwMC0wMDAwLTAwMDAtMDAwMC0wMDAwMDAwMDAwMDAiLCJ3b3Jrc3BhY2VJZCI6IjQ4NWU0NzI2LTEyNmYtNGFhMy05NmVhLTQ2ZTdlZWM4ZmMyNyIsInByb2plY3RpZCI6IjAwMDAwMDAwLTAwMDAtMDAwMC0wMDAwLTAwMDAwMDAwMDAwMCIsImRpc2NvdmVyeSI6InVyaTovL2Rpc2NvdmVyeXVyaS8iLCJ0aWQiOiJkNjc1NTIzMy00NmFmLTQwMzAtODkwNi0wNTdiZDI5YTllZTgiLCJvaWQiOiI5MTdlOTk2Yi0yNmU3LTQ3NWEtOTMyNC0xNWEzNWQ1OTBkYTAiLCJwdWlkIjoiMTAwMzIwMDIwMDlFODhFRCIsImlzcyI6ImF6dXJlbWwiLCJhcHBpZCI6Iu2YleynhCDquYAiLCJleHAiOjE2Njc3MzIyMjQsImF1ZCI6ImF6dXJlbWwifQ.WFfMj0FOYB_ejXjtZSW_9su5nJzs66IXbpjQn2h_XF8XLvJTvfdUhcYV1a-oqosPvOMrpR9aon0KQHyki1KNFRQdgxBmfX8fiPTNs6HmuNN7cU1crp_kduyu4zi_e3x1XJl07mozjIZDOF1X5j9U-gGAThWDWpUBhv-2m7dDoE-XMbEstXvEbBKV65QznAUm8fL3N-s7fhFEAe1USY1jePrvH3RCSrUMU8zd393bnVJ5oadFrpTrzaWrJBdfxgWRhbyQEKCJAM4YlXFkKpLGBV7YoWNUqHBFlwYPYIPEdj0UW9x-5AcuhP2tSqg7LfDJAy2w0Mw8NAwn6hwLEJhh1A\\', \\'-e\\', \\'AZUREML_ROOT_RUN_ID=mslearn-diabetes_1665910669_53b5ce9f\\', \\'-e\\', \\'AZUREML_COMPUTE_RECORD_ARTIFACT_ORIGIN=ComputeRecord\\', \\'-e\\', \\'AZUREML_COMPUTE_RECORD_ARTIFACT_PATH=compute_record.txt\\', \\'-e\\', \\'HBI_WORKSPACE_JOB=false\\', \\'-e\\', \\'AZUREML_RUN_TOKEN_RAND=d3465fc8-545b-424a-bed6-35b8c8b53697\\', \\'-e\\', \\'AZUREML_RUN_TOKEN_PASS=e07a2721-ea29-4645-9773-449042b23c98\\', \\'-e\\', \\'PYTHONUNBUFFERED=True\\', \\'-e\\', \\'AZUREML_COMMUNICATOR=None\\', \\'-e\\', \\'AZUREML_FRAMEWORK=Python\\', \\'-e\\', \\'AZUREML_EXPERIMENT_ID=9fa555db-d343-4e0b-9e62-5e8a7fe8c939\\', \\'-e\\', \\'AZUREML_ARM_PROJECT_NAME=mslearn-diabetes\\', \\'-e\\', \\'AZUREML_ARM_WORKSPACE_NAME=exercise_deep_neural_network\\', \\'-e\\', \\'AZUREML_ARM_SUBSCRIPTION=fe87babe-9ce9-43f8-b0aa-70603823aca8\\', \\'-e\\', \\'AZUREML_ARM_RESOURCEGROUP=exercise_train_a_deep_neural_network\\', \\'-e\\', \\'AZUREML_EXPERIMENT_SCOPE=/subscriptions/fe87babe-9ce9-43f8-b0aa-70603823aca8/resourceGroups/exercise_train_a_deep_neural_network/providers/Microsoft.MachineLearningServices/workspaces/exercise_deep_neural_network/experiments/mslearn-diabetes\\', \\'-e\\', \\'AZUREML_WORKSPACE_ID=485e4726-126f-4aa3-96ea-46e7eec8fc27\\', \\'-e\\', \\'AZUREML_WORKSPACE_SCOPE=/subscriptions/fe87babe-9ce9-43f8-b0aa-70603823aca8/resourceGroups/exercise_train_a_deep_neural_network/providers/Microsoft.MachineLearningServices/workspaces/exercise_deep_neural_network\\', \\'-e\\', \\'AZUREML_DATA_CONTAINER_ID=dcid.mslearn-diabetes_1665910669_53b5ce9f\\', \\'-e\\', \\'AZUREML_DISCOVERY_SERVICE_ENDPOINT=https://koreacentral.api.azureml.ms/discovery\\', \\'-e\\', \\'AZUREML_RUN_HISTORY_SERVICE_ENDPOINT=https://koreacentral.api.azureml.ms\\', \\'-e\\', \\'AZUREML_SERVICE_ENDPOINT=https://koreacentral.api.azureml.ms\\', \\'-e\\', \\'AZUREML_RUN_CONFIGURATION=azureml-setup/mutated_run_configuration.json\\', \\'-e\\', \\'AZUREML_INSTRUMENTATION_KEY=7c242b89-6163-4a24-aef0-2bc10f8217d0\\', \\'-e\\', \\'AZUREML_DRIVERLOG_PATH=azureml-logs/driver_log.txt\\', \\'-e\\', \\'TELEMETRY_LOGS=azureml-logs/telemetry_logs/\\', \\'-e\\', \\'FAIRLEARN_LOGS=azureml-logs/telemetry_logs/fairlearn_log.txt\\', \\'-e\\', \\'INTERPRET_TEXT_LOGS=azureml-logs/telemetry_logs/interpret_text_log.txt\\', \\'-e\\', \\'INTERPRET_C_LOGS=azureml-logs/telemetry_logs/interpret_community_log.txt\\', \\'-e\\', \\'AZUREML_JOBRELEASELOG_PATH=azureml-logs/job_release_log.txt\\', \\'-e\\', \\'AZUREML_JOBPREPLOG_PATH=azureml-logs/job_prep_log.txt\\', \\'-e\\', \\'AZUREML_CONTROLLOG_PATH=azureml-logs/control_log.txt\\', \\'-e\\', \\'AZUREML_LOGDIRECTORY_PATH=azureml-logs/\\', \\'-e\\', \\'AZUREML_PIDFILE_PATH=azureml-setup/pid.txt\\', \\'-e\\', \\'AZUREML_RUN_ID=mslearn-diabetes_1665910669_53b5ce9f\\', \\'azureml/azureml_ebb14aaae0caf88689036382aa234cf7\\', \\'/bin/bash\\', \\'-c\\', \\'cd /azureml-run && \"/azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/bin/python\" \"azureml-setup/run_script.py\" \"/azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/bin/python\" \"azureml-setup/context_manager_injector.py\" \"-i\" \"ProjectPythonPath:context_managers.ProjectPythonPath\" \"-i\" \"RunHistory:context_managers.RunHistory\" \"-i\" \"TrackUserError:context_managers.TrackUserError\" \"diabetes_experiment.py\"\\']\\nStreaming log file azureml-logs/70_driver_log.txt\\nStarting the daemon thread to refresh tokens in background for process with pid = 1\\nScript process exited with code 0\\nUploading driver log...\\nFinalizing run...\\n[2022-10-16T09:02:04.593895] get vm size and vm region successfully.\\n[2022-10-16T09:02:04.600276] get compute meta data successfully.\\n[2022-10-16T09:02:04.679462] post artifact meta request successfully.\\n[2022-10-16T09:02:04.712045] upload compute record artifact successfully.\\n\\nScript process exited with code 0\\n\\n\\n\\nUploading control log...\\n',\n  'azureml-logs/70_driver_log.txt': \"[2022-10-16T09:01:54.505934] Entering context manager injector.\\nCannot provide tracer without any exporter configured.\\n/azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages/paramiko/transport.py:33: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.\\n  from cryptography.hazmat.backends import default_backend\\n[2022-10-16T09:01:55.387355] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['diabetes_experiment.py'])\\nScript type = None\\n[2022-10-16T09:01:55.390946] Entering Run History Context Manager.\\n/azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages/azureml/history/_tracking.py:367: FutureWarning: azureml.core: AzureML support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use AzureML will continue to work without modification, but Python 3.6 users will no longer get access to the latest AzureML features and bugfixes. We recommend that you upgrade to Python 3.7 or newer. To disable SDK V1 deprecation warning set the environment variable AZUREML_DEPRECATE_WARNING to 'False'\\n  from azureml.core.run import Run\\n/azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages/azureml/history/_tracking.py:186: FutureWarning: MLflow support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use MLflow will continue to work without modification, but Python 3.6 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3.7 or newer.\\n  import mlflow\\n[2022-10-16T09:01:57.523174] Current directory: /azureml-run\\n[2022-10-16T09:01:57.523208] Preparing to call script [diabetes_experiment.py] with arguments:[]\\n[2022-10-16T09:01:57.523225] After variable expansion, calling script [diabetes_experiment.py] with arguments:[]\\n\\nAnalyzing 10000 rows of data\\n0    6656\\n1    3344\\nName: Diabetic, dtype: int64\\n\\n\\n[2022-10-16T09:02:03.268311] The experiment completed successfully. Finalizing run...\\n[2022-10-16T09:02:03.268330] Start FinalizingInRunHistory\\n[2022-10-16T09:02:03.270025] Logging experiment finalizing status in history service.\\nStarting the daemon thread to refresh tokens in background for process with pid = 9\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\n2 items cleaning up...\\nCleanup took 0.08803200721740723 seconds\\n[2022-10-16T09:02:04.160972] Finished context manager injector.\\n\",\n  'logs/azureml/9_azureml.log': \"2022-10-16 09:01:55,391|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True}, track_folders: None, deny_list: None, directories_to_watch: ['logs', 'logs/azureml']\\n2022-10-16 09:01:55,392|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: none\\n2022-10-16 09:01:55,392|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2022-10-16 09:01:55,392|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2022-10-16 09:01:56,053|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7f637bdab400> for run source azureml.scriptrun\\n2022-10-16 09:01:56,056|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2022-10-16 09:01:56,056|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2022-10-16 09:01:56,063|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2022-10-16 09:01:56,077|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2022-10-16 09:01:56,077|azureml.core.authentication|DEBUG|Time to expire 1821307.922818 seconds\\n2022-10-16 09:01:56,077|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2022-10-16 09:01:56,077|azureml._restclient.clientbase|DEBUG|ClientBase: Calling get with url None\\n2022-10-16 09:01:56,108|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://koreacentral.api.azureml.ms.\\n2022-10-16 09:01:56,109|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://koreacentral.api.azureml.ms.\\n2022-10-16 09:01:56,109|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://koreacentral.api.azureml.ms.\\n2022-10-16 09:01:56,109|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://koreacentral.api.azureml.ms.\\n2022-10-16 09:01:56,110|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://koreacentral.api.azureml.ms.\\n2022-10-16 09:01:56,110|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://koreacentral.api.azureml.ms.\\n2022-10-16 09:01:56,110|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://koreacentral.api.azureml.ms.\\n2022-10-16 09:01:56,275|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2022-10-16 09:01:56,276|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2022-10-16 09:01:56,336|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2022-10-16 09:01:56,337|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': '0ea02dc3-3d76-4b32-8f7d-5563c2ca006b'}\\n2022-10-16 09:01:56,337|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2022-10-16 09:01:57,177|azureml|DEBUG|Installed with mlflow version 1.23.1.\\n2022-10-16 09:01:57,178|azureml.mlflow|DEBUG|Setting up a Remote MLflow run\\n2022-10-16 09:01:57,301|azureml.mlflow|DEBUG|Creating a tracking uri in koreacentral.api.azureml.ms for workspace /subscriptions/fe87babe-9ce9-43f8-b0aa-70603823aca8/resourceGroups/exercise_train_a_deep_neural_network/providers/Microsoft.MachineLearningServices/workspaces/exercise_deep_neural_network\\n2022-10-16 09:01:57,301|azureml.mlflow|DEBUG|Setting MLflow tracking uri env var\\n2022-10-16 09:01:57,302|azureml.mlflow|DEBUG|Setting MLflow run id env var with mslearn-diabetes_1665910669_53b5ce9f\\n2022-10-16 09:01:57,302|azureml.mlflow|DEBUG|Setting Mlflow experiment with mslearn-diabetes\\n2022-10-16 09:01:57,302|azureml.mlflow|DEBUG|Setting Mlflow experiment with 9fa555db-d343-4e0b-9e62-5e8a7fe8c939\\n2022-10-16 09:01:57,303|azureml.mlflow|DEBUG|Setting the mlflow tag mlflow.source.type\\n2022-10-16 09:01:57,303|azureml.mlflow|DEBUG|Setting the mlflow tag mlflow.source.name\\n2022-10-16 09:01:57,303|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.RunClient.get_details-async:False|DEBUG|[START]\\n2022-10-16 09:01:57,304|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_details with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/details\\n2022-10-16 09:01:57,374|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.RunClient.get_details-async:False|DEBUG|[STOP]\\n2022-10-16 09:01:57,377|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient|DEBUG|Fetching files for prefix in ExperimentRun, dcid.mslearn-diabetes_1665910669_53b5ce9f, user_logs\\n2022-10-16 09:01:57,377|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix-async:True|DEBUG|[START]\\n2022-10-16 09:01:57,377|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _execute_with_base_arguments\\n2022-10-16 09:01:57,378|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling list_sas_by_prefix with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/prefix/contentinfo/{origin}/{container}/{path}\\n2022-10-16 09:01:57,378|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix|DEBUG|Using basic handler - no exception handling\\n2022-10-16 09:01:57,381|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix-async:True|DEBUG|[STOP]\\n2022-10-16 09:01:57,382|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|[START]\\n2022-10-16 09:01:57,382|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|Awaiter is ApiPagination\\n2022-10-16 09:01:57,419|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|[STOP]\\n2022-10-16 09:01:57,419|azureml._restclient.clientbase|DEBUG|Found continuation_token field in DTO\\n2022-10-16 09:01:57,420|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient|DEBUG|Fetching files for prefix in ExperimentRun, dcid.mslearn-diabetes_1665910669_53b5ce9f, system_logs\\n2022-10-16 09:01:57,420|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix-async:True|DEBUG|[START]\\n2022-10-16 09:01:57,421|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _execute_with_base_arguments\\n2022-10-16 09:01:57,421|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling list_sas_by_prefix with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/prefix/contentinfo/{origin}/{container}/{path}\\n2022-10-16 09:01:57,424|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix|DEBUG|Using basic handler - no exception handling\\n2022-10-16 09:01:57,424|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix-async:True|DEBUG|[STOP]\\n2022-10-16 09:01:57,424|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|[START]\\n2022-10-16 09:01:57,424|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|Awaiter is ApiPagination\\n2022-10-16 09:01:57,463|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|[STOP]\\n2022-10-16 09:01:57,463|azureml._restclient.clientbase|DEBUG|Found continuation_token field in DTO\\n2022-10-16 09:01:57,464|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[START]\\n2022-10-16 09:01:57,464|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling patch_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2022-10-16 09:01:57,520|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[STOP]\\n2022-10-16 09:01:57,520|azureml.WorkerPool|DEBUG|[START]\\n2022-10-16 09:01:57,520|azureml.SendRunKillSignal|DEBUG|[START]\\n2022-10-16 09:01:57,520|azureml.RunStatusContext|DEBUG|[START]\\n2022-10-16 09:01:57,520|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunContextManager.RunStatusContext|DEBUG|[START]\\n2022-10-16 09:01:57,520|azureml.MetricsClient|DEBUG|[START]\\n2022-10-16 09:01:57,520|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2022-10-16 09:01:57,521|azureml.ContentUploader|DEBUG|[START]\\n2022-10-16 09:01:57,521|azureml._history.utils.context_managers|DEBUG|starting file watcher\\n2022-10-16 09:01:57,522|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Start]\\n2022-10-16 09:01:57,522|azureml.TrackFolders|DEBUG|[START]\\n2022-10-16 09:01:57,522|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2022-10-16 09:01:57,522|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2022-10-16 09:01:57,522|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /azureml-run\\n2022-10-16 09:01:57,522|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2022-10-16 09:01:57,523|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /azureml-run\\n2022-10-16 09:01:57,536|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2022-10-16 09:01:57,537|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2022-10-16 09:01:57,537|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2022-10-16 09:01:57,537|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2022-10-16 09:01:57,537|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2022-10-16 09:01:57,541|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://koreacentral.api.azureml.ms.\\n2022-10-16 09:01:57,541|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://koreacentral.api.azureml.ms.\\n2022-10-16 09:01:57,542|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://koreacentral.api.azureml.ms.\\n2022-10-16 09:01:57,542|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://koreacentral.api.azureml.ms.\\n2022-10-16 09:01:57,542|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://koreacentral.api.azureml.ms.\\n2022-10-16 09:01:57,542|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://koreacentral.api.azureml.ms.\\n2022-10-16 09:01:57,543|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://koreacentral.api.azureml.ms.\\n2022-10-16 09:01:57,580|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2022-10-16 09:01:57,581|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2022-10-16 09:01:57,629|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2022-10-16 09:01:57,630|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': '0ea02dc3-3d76-4b32-8f7d-5563c2ca006b'}\\n2022-10-16 09:01:57,630|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2022-10-16 09:01:57,647|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2022-10-16 09:01:57,648|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2022-10-16 09:01:57,649|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2022-10-16 09:01:57,656|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2022-10-16 09:01:57,667|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f|INFO|complete is not setting status for submitted runs.\\n2022-10-16 09:01:57,668|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2022-10-16 09:01:57,668|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2022-10-16 09:01:57,668|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2022-10-16 09:01:57,669|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2022-10-16 09:01:57,669|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2022-10-16 09:01:57,669|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2022-10-16 09:01:57,669|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2022-10-16 09:01:57,669|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2022-10-16 09:01:57,669|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2022-10-16 09:01:57,669|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2022-10-16 09:01:57,670|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2022-10-16 09:01:57,672|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 3.\\n2022-10-16 09:01:57,673|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2022-10-16 09:01:57,673|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2022-10-16 09:01:57,673|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2022-10-16 09:01:57,673|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2022-10-16 09:01:57,673|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2022-10-16 09:01:57,673|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2022-10-16 09:01:57,673|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2022-10-16 09:01:57,673|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 3 values.\\n2022-10-16 09:01:57,673|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2022-10-16 09:01:57,674|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2022-10-16 09:01:57,678|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2022-10-16 09:01:57,678|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2022-10-16 09:01:57,704|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.mslearn-diabetes_1665910669_53b5ce9f/logs/azureml/9_azureml.log path: /azureml-run/logs/azureml/9_azureml.log\\n2022-10-16 09:01:57,704|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-10-16 09:01:57,704|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result|DEBUG|Using basic handler - no exception handling\\n2022-10-16 09:01:57,705|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 0_result to queue of approximate size: 0\\n2022-10-16 09:01:57,924|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2022-10-16 09:01:57,924|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2022-10-16 09:01:57,924|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2022-10-16 09:01:57,924|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Waiting on task: 0__handle_batch.\\n1 tasks left. Current duration of flush 9.059906005859375e-05 seconds.\\n\\n2022-10-16 09:01:57,924|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2022-10-16 09:01:57,924|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2022-10-16 09:01:57,924|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2022-10-16 09:01:57,924|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0__log_batch_v2)].\\n2022-10-16 09:01:57,931|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2022-10-16 09:01:58,175|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2022-10-16 09:01:58,175|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2022-10-16 09:01:58,175|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2022-10-16 09:01:58,175|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Waiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 0.00017881393432617188 seconds.\\n\\n2022-10-16 09:01:58,175|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2022-10-16 09:01:58,175|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2022-10-16 09:01:58,175|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2022-10-16 09:01:58,176|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2022-10-16 09:01:58,223|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2022-10-16 09:02:03,229|azureml._restclient.clientbase|DEBUG|ClientBase: Calling update_status with url None\\n2022-10-16 09:02:03,267|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: [], excluding []\\n2022-10-16 09:02:03,268|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2022-10-16 09:02:03,337|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2022-10-16 09:02:03,337|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /azureml-run\\n2022-10-16 09:02:03,337|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /azureml-run to /azureml-run\\n2022-10-16 09:02:03,337|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /azureml-run\\n2022-10-16 09:02:03,338|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2022-10-16 09:02:03,338|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2022-10-16 09:02:03,338|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: ['./outputs'], excluding ['azureml-logs/driver_log']\\n2022-10-16 09:02:03,338|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2022-10-16 09:02:03,338|azureml.history._tracking.PythonWorkingDirectory|DEBUG|./outputs exists as directory, uploading..\\n2022-10-16 09:02:03,338|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Found and adding path to upload: ./outputs/sample.csv\\n2022-10-16 09:02:03,338|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Paths to upload is ['./outputs/sample.csv'] in dir ./outputs\\n2022-10-16 09:02:03,338|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Overriding default timeout to 300\\n2022-10-16 09:02:03,338|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Start]\\n2022-10-16 09:02:03,338|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2022-10-16 09:02:03,338|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2022-10-16 09:02:03,417|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2022-10-16 09:02:03,417|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: perform_upload\\n2022-10-16 09:02:03,419|azureml._restclient.clientbase|DEBUG|ClientBase: Calling upload_blob with url None\\n2022-10-16 09:02:03,423|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload|DEBUG|Using basic handler - no exception handling\\n2022-10-16 09:02:03,423|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Adding task 0_perform_upload to queue of approximate size: 0\\n2022-10-16 09:02:03,423|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Stop] - waiting default timeout\\n2022-10-16 09:02:03,424|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[START]\\n2022-10-16 09:02:03,424|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Overriding default flush timeout from None to 300\\n2022-10-16 09:02:03,424|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0_perform_upload)].\\n2022-10-16 09:02:03,472|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.mslearn-diabetes_1665910669_53b5ce9f/outputs/sample.csv with size 5562, file size 5562.\\n2022-10-16 09:02:03,674|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[START]\\n2022-10-16 09:02:03,674|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|Awaiter is upload_files\\n2022-10-16 09:02:03,674|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[STOP]\\n2022-10-16 09:02:03,675|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Waiting on task: 0_perform_upload.\\n1 tasks left. Current duration of flush 9.131431579589844e-05 seconds.\\n\\n2022-10-16 09:02:03,675|azureml._SubmittedRun#mslearn-diabetes_1665910669_53b5ce9f.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[STOP]\\n2022-10-16 09:02:03,675|azureml.TrackFolders|DEBUG|[STOP]\\n2022-10-16 09:02:03,675|azureml._history.utils.context_managers|DEBUG|exiting ContentUploader, waiting for file_watcher to finish upload...\\n2022-10-16 09:02:03,675|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher called finish, setting event\\n2022-10-16 09:02:03,675|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher received exit event, getting current_stat\\n2022-10-16 09:02:03,675|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-10-16 09:02:03,680|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result|DEBUG|Using basic handler - no exception handling\\n2022-10-16 09:02:03,680|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 1_result to queue of approximate size: 1\\n2022-10-16 09:02:03,680|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher retrieved current_stat, will upload to current_stat\\n2022-10-16 09:02:03,680|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,681|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,681|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,681|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,681|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,681|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,682|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,682|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,682|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,682|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,682|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,683|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,683|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,683|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,683|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,683|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,683|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,684|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,684|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,684|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,684|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,685|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,685|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,685|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,685|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,685|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,686|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,686|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-10-16 09:02:03,687|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-10-16 09:02:03,689|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result|DEBUG|Using basic handler - no exception handling\\n2022-10-16 09:02:03,689|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 2_result to queue of approximate size: 2\\n2022-10-16 09:02:03,689|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher finished uploading to current_stat, finishing task queue\\n2022-10-16 09:02:03,690|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Stop] - waiting default timeout\\n2022-10-16 09:02:03,693|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[START]\\n2022-10-16 09:02:03,693|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Overriding default flush timeout from None to 120\\n2022-10-16 09:02:03,693|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0_result), AsyncTask(1_result), AsyncTask(2_result)].\\n2022-10-16 09:02:03,693|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[START]\\n2022-10-16 09:02:03,693|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-10-16 09:02:03,693|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[STOP]\\n2022-10-16 09:02:03,693|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[START]\\n2022-10-16 09:02:03,693|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-10-16 09:02:03,694|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[STOP]\\n2022-10-16 09:02:03,944|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[START]\\n2022-10-16 09:02:03,944|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-10-16 09:02:03,944|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[STOP]\\n2022-10-16 09:02:03,944|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Waiting on task: 2_result.\\n1 tasks left. Current duration of flush 0.0006287097930908203 seconds.\\n\\n2022-10-16 09:02:03,944|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[STOP]\\n\"},\n 'submittedBy': '형진 김'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1665910927297
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although you can view the log details in the output above, it's usually easier to download the log files and view them in a text editor."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "log_folder = 'downloaded-logs'\n",
        "\n",
        "# Download all files\n",
        "run.get_all_logs(destination=log_folder)\n",
        "\n",
        "# Verify the files have been downloaded\n",
        "for root, directories, filenames in os.walk(log_folder): \n",
        "    for filename in filenames:  \n",
        "        print (os.path.join(root,filename))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "downloaded-logs/azureml-logs/60_control_log.txt\ndownloaded-logs/azureml-logs/70_driver_log.txt\ndownloaded-logs/logs/azureml/9_azureml.log\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1665910927746
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View experiment run history\n",
        "\n",
        "Now that you've run the same experiment multiple times, you can view the history in [Azure Machine Learning studio](https://ml.azure.com) and explore each logged run. Or you can retrieve an experiment by name from the workspace and iterate through its runs using the SDK:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment, Run\n",
        "\n",
        "diabetes_experiment = ws.experiments['mslearn-diabetes']\n",
        "for logged_run in diabetes_experiment.get_runs():\n",
        "    print('Run ID:', logged_run.id)\n",
        "    metrics = logged_run.get_metrics()\n",
        "    for key in metrics.keys():\n",
        "        print('-', key, metrics.get(key))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Run ID: mslearn-diabetes_1665910669_53b5ce9f\n- observations 10000\n- Label:0 6656\n- Label:1 3344\nRun ID: 21ed9a8a-dd0c-49f5-9327-d0fd3aa09697\n- observations 10000\n- label distribution aml://artifactId/ExperimentRun/dcid.21ed9a8a-dd0c-49f5-9327-d0fd3aa09697/label distribution_1665910628.png\n- pregnancy categories [0, 8, 7, 9, 1, 3, 5, 2, 6, 11, 4, 13, 10, 12, 14]\n- PlasmaGlucose {'stat': ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], 'value': [10000.0, 107.8502, 31.920909360565563, 44.0, 84.0, 105.0, 129.0, 192.0]}\n- DiastolicBloodPressure {'stat': ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], 'value': [10000.0, 71.2075, 16.801478289640706, 24.0, 58.0, 72.0, 85.0, 117.0]}\n- TricepsThickness {'stat': ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], 'value': [10000.0, 28.8176, 14.506480415228332, 7.0, 15.0, 31.0, 41.0, 92.0]}\n- SerumInsulin {'stat': ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], 'value': [10000.0, 139.2436, 133.77791937465278, 14.0, 39.0, 85.0, 197.0, 796.0]}\n- BMI {'stat': ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], 'value': [10000.0, 31.56702174359113, 9.804365693559113, 18.20080735, 21.247426835, 31.922420785, 39.3289214475, 56.03462763]}\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1665910929102
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use MLflow\n",
        "\n",
        "MLflow is an open source platform for managing machine learning processes. It's commonly (but not exclusively) used in Databricks environments to coordinate experiments and track metrics. In Azure Machine Learning experiments, you can use MLflow to track metrics as an alternative to the native log functionality.\n",
        "\n",
        "To take advantage of this capability, you'll need the **azureml-mlflow** package, so let's ensure it's installed."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pip show azureml-mlflow"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Name: azureml-mlflow\r\nVersion: 1.44.0\r\nSummary: Contains the integration code of AzureML with Mlflow.\r\nHome-page: https://docs.microsoft.com/python/api/overview/azure/ml/?view=azure-ml-py\r\nAuthor: Microsoft Corp\r\nAuthor-email: None\r\nLicense: Proprietary https://aka.ms/azureml-preview-sdk-license \r\nLocation: /anaconda/envs/azureml_py38/lib/python3.8/site-packages\r\nRequires: azure-mgmt-core, cryptography, azure-storage-blob, azure-core, python-dateutil, azure-common, msrest, mlflow-skinny, azure-identity, jsonpickle\r\nRequired-by: azureml-train-automl-runtime\r\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1665910933714
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use MLflow with an inline experiment\n",
        "\n",
        "To use MLflow to track metrics for an inline experiment, you must set the MLflow *tracking URI* to the workspace where the experiment is being run. This enables you to use **mlflow** tracking methods to log data to the experiment run."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "import pandas as pd\n",
        "import mlflow\n",
        "\n",
        "# Set the MLflow tracking URI to the workspace\n",
        "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
        "\n",
        "# Create an Azure ML experiment in your workspace\n",
        "experiment = Experiment(workspace=ws, name='mslearn-diabetes-mlflow')\n",
        "mlflow.set_experiment(experiment.name)\n",
        "\n",
        "# start the MLflow experiment\n",
        "with mlflow.start_run():\n",
        "    \n",
        "    print(\"Starting experiment:\", experiment.name)\n",
        "    \n",
        "    # Load data\n",
        "    data = pd.read_csv('data/diabetes.csv')\n",
        "\n",
        "    # Count the rows and log the result\n",
        "    row_count = (len(data))\n",
        "    mlflow.log_metric('observations', row_count)\n",
        "    print(\"Run complete\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Starting experiment: mslearn-diabetes-mlflow\nRun complete\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1665910937073
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's look at the metrics logged during the run"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the latest run of the experiment\n",
        "run = list(experiment.get_runs())[0]\n",
        "\n",
        "# Get logged metrics\n",
        "print(\"\\nMetrics:\")\n",
        "metrics = run.get_metrics()\n",
        "for key in metrics.keys():\n",
        "        print(key, metrics.get(key))\n",
        "    \n",
        "# Get a link to the experiment in Azure ML studio   \n",
        "experiment_url = experiment.get_portal_url()\n",
        "print('See details at', experiment_url)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nMetrics:\nobservations 10000.0\nSee details at https://ml.azure.com/experiments/id/068f3bd0-b3cf-4e46-a645-f624a8504dad?wsid=/subscriptions/fe87babe-9ce9-43f8-b0aa-70603823aca8/resourcegroups/exercise_train_a_deep_neural_network/workspaces/exercise_deep_neural_network&tid=d6755233-46af-4030-8906-057bd29a9ee8\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1665911190650
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After running the code above, you can use the link that is displayed to view the experiment in Azure Machine Learning studio. Then select the latest run of the experiment and view its **Metrics** tab to see the logged metric.\n",
        "\n",
        "### Use MLflow in an experiment script\n",
        "\n",
        "You can also use MLflow to track metrics in an experiment script.\n",
        "\n",
        "Run the following two cells to create a folder and a script for an experiment that uses MLflow."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "\n",
        "# Create a folder for the experiment files\n",
        "folder_name = 'mlflow-experiment-files'\n",
        "experiment_folder = './' + folder_name\n",
        "os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "# Copy the data file into the experiment folder\n",
        "shutil.copy('data/diabetes.csv', os.path.join(folder_name, \"diabetes.csv\"))"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "'mlflow-experiment-files/diabetes.csv'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1665911199524
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $folder_name/mlflow_diabetes.py\n",
        "from azureml.core import Run\n",
        "import pandas as pd\n",
        "import mlflow\n",
        "\n",
        "\n",
        "# start the MLflow experiment\n",
        "with mlflow.start_run():\n",
        "       \n",
        "    # Load data\n",
        "    data = pd.read_csv('diabetes.csv')\n",
        "\n",
        "    # Count the rows and log the result\n",
        "    row_count = (len(data))\n",
        "    print('observations:', row_count)\n",
        "    mlflow.log_metric('observations', row_count)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing mlflow-experiment-files/mlflow_diabetes.py\n"
        }
      ],
      "execution_count": 20,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you use MLflow tracking in an Azure ML experiment script, the MLflow tracking URI is set automatically when you start the experiment run. However, the environment in which the script is to be run must include the required **mlflow** packages."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
        "from azureml.core.runconfig import DockerConfiguration\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "\n",
        "# Create a Python environment for the experiment (from a .yml file)\n",
        "env = Environment.from_conda_specification(\"experiment_env\", \"environment.yml\")\n",
        "\n",
        "# Create a script config\n",
        "script_mlflow = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                                script='mlflow_diabetes.py',\n",
        "                                environment=env,\n",
        "                                docker_runtime_config=DockerConfiguration(use_docker=True)) \n",
        "\n",
        "# submit the experiment\n",
        "experiment = Experiment(workspace=ws, name='mslearn-diabetes-mlflow')\n",
        "run = experiment.submit(config=script_mlflow)\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e709a01bfbf4c518b135fc199213ce2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/mslearn-diabetes-mlflow_1665911211_cd522cb6?wsid=/subscriptions/fe87babe-9ce9-43f8-b0aa-70603823aca8/resourcegroups/exercise_train_a_deep_neural_network/workspaces/exercise_deep_neural_network&tid=d6755233-46af-4030-8906-057bd29a9ee8\", \"run_id\": \"mslearn-diabetes-mlflow_1665911211_cd522cb6\", \"run_properties\": {\"run_id\": \"mslearn-diabetes-mlflow_1665911211_cd522cb6\", \"created_utc\": \"2022-10-16T09:06:51.499155Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"9f81a20f-bcc6-4cc2-bf39-18557bad155f\"}, \"tags\": {\"mlflow.source.type\": \"JOB\", \"mlflow.source.name\": \"mlflow_diabetes.py\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2022-10-16T09:06:59.214057Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://exercisedeepne4107602632.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes-mlflow_1665911211_cd522cb6/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=PNKDZGy3N4hq3RoYn5IbtFmg7ftV8cEX%2FqLm1XXjVaQ%3D&skoid=f7312be2-3e76-4d30-b80f-d3839b51041e&sktid=d6755233-46af-4030-8906-057bd29a9ee8&skt=2022-10-16T08%3A47%3A10Z&ske=2022-10-17T16%3A57%3A10Z&sks=b&skv=2019-07-07&st=2022-10-16T08%3A57%3A03Z&se=2022-10-16T17%3A07%3A03Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://exercisedeepne4107602632.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes-mlflow_1665911211_cd522cb6/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=qdUVVZ8M5S8s9vgzuSsVzbMtbS24tkjfBdlmQmHye7k%3D&skoid=f7312be2-3e76-4d30-b80f-d3839b51041e&sktid=d6755233-46af-4030-8906-057bd29a9ee8&skt=2022-10-16T08%3A47%3A10Z&ske=2022-10-17T16%3A57%3A10Z&sks=b&skv=2019-07-07&st=2022-10-16T08%3A57%3A03Z&se=2022-10-16T17%3A07%3A03Z&sp=r\", \"logs/azureml/7_azureml.log\": \"https://exercisedeepne4107602632.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes-mlflow_1665911211_cd522cb6/logs/azureml/7_azureml.log?sv=2019-07-07&sr=b&sig=GNV1KzrNJFuUHDoIDDNgvpTg0o85QGdA%2FtO5i7IGLZg%3D&skoid=f7312be2-3e76-4d30-b80f-d3839b51041e&sktid=d6755233-46af-4030-8906-057bd29a9ee8&skt=2022-10-16T08%3A47%3A10Z&ske=2022-10-17T16%3A57%3A10Z&sks=b&skv=2019-07-07&st=2022-10-16T08%3A56%3A58Z&se=2022-10-16T17%3A06%3A58Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/7_azureml.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"]], \"run_duration\": \"0:00:07\", \"run_number\": \"1665911211\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"observations\", \"run_id\": \"mslearn-diabetes-mlflow_1665911211_cd522cb6\", \"categories\": [0], \"series\": [{\"data\": [10000.0]}]}], \"run_logs\": \"[2022-10-16T09:06:53.763643] Entering context manager injector.\\nCannot provide tracer without any exporter configured.\\n/azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages/paramiko/transport.py:33: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.\\n  from cryptography.hazmat.backends import default_backend\\n[2022-10-16T09:06:54.633072] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['mlflow_diabetes.py'])\\nScript type = None\\n[2022-10-16T09:06:54.636531] Entering Run History Context Manager.\\n/azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages/azureml/history/_tracking.py:367: FutureWarning: azureml.core: AzureML support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use AzureML will continue to work without modification, but Python 3.6 users will no longer get access to the latest AzureML features and bugfixes. We recommend that you upgrade to Python 3.7 or newer. To disable SDK V1 deprecation warning set the environment variable AZUREML_DEPRECATE_WARNING to 'False'\\n  from azureml.core.run import Run\\n/azureml-envs/azureml_809a074975457de1dd27bdfcf2d79d61/lib/python3.6/site-packages/azureml/history/_tracking.py:186: FutureWarning: MLflow support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use MLflow will continue to work without modification, but Python 3.6 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3.7 or newer.\\n  import mlflow\\n[2022-10-16T09:06:56.690758] Current directory: /azureml-run\\n[2022-10-16T09:06:56.690826] Preparing to call script [mlflow_diabetes.py] with arguments:[]\\n[2022-10-16T09:06:56.690864] After variable expansion, calling script [mlflow_diabetes.py] with arguments:[]\\n\\nobservations: 10000\\n\\n\\n[2022-10-16T09:06:57.544410] The experiment completed successfully. Finalizing run...\\n[2022-10-16T09:06:57.544430] Start FinalizingInRunHistory\\n[2022-10-16T09:06:57.546039] Logging experiment finalizing status in history service.\\nStarting the daemon thread to refresh tokens in background for process with pid = 7\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\n1 items cleaning up...\\nCleanup took 0.04100990295410156 seconds\\n[2022-10-16T09:06:58.017731] Finished context manager injector.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.44.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "{'runId': 'mslearn-diabetes-mlflow_1665911211_cd522cb6',\n 'target': 'local',\n 'status': 'Finalizing',\n 'startTimeUtc': '2022-10-16T09:06:52.749914Z',\n 'services': {},\n 'properties': {'_azureml.ComputeTargetType': 'local',\n  'ContentSnapshotId': '9f81a20f-bcc6-4cc2-bf39-18557bad155f'},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'runDefinition': {'script': 'mlflow_diabetes.py',\n  'command': '',\n  'useAbsolutePath': False,\n  'arguments': [],\n  'sourceDirectoryDataStore': None,\n  'framework': 'Python',\n  'communicator': 'None',\n  'target': 'local',\n  'dataReferences': {},\n  'data': {},\n  'outputData': {},\n  'datacaches': [],\n  'jobName': None,\n  'maxRunDurationSeconds': 2592000,\n  'nodeCount': 1,\n  'instanceTypes': [],\n  'priority': None,\n  'credentialPassthrough': False,\n  'identity': None,\n  'environment': {'name': 'experiment_env',\n   'version': 'Autosave_2022-10-16T08:57:50Z_1ee1058a',\n   'assetId': 'azureml://locations/koreacentral/workspaces/485e4726-126f-4aa3-96ea-46e7eec8fc27/environments/experiment_env/versions/Autosave_2022-10-16T08:57:50Z_1ee1058a',\n   'autoRebuild': True,\n   'python': {'interpreterPath': 'python',\n    'userManagedDependencies': False,\n    'condaDependencies': {'dependencies': ['python=3.6.2',\n      'scikit-learn',\n      'pandas',\n      'pip',\n      {'pip': ['azureml-defaults', 'azureml-mlflow']}],\n     'name': 'simple_environment'},\n    'baseCondaEnvironment': None},\n   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1',\n    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n    'baseDockerfile': None,\n    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n    'enabled': False,\n    'arguments': []},\n   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n   'inferencingStackVersion': None},\n  'history': {'outputCollection': True,\n   'directoriesToWatch': ['logs'],\n   'enableMLflowTracking': True,\n   'snapshotProject': True},\n  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n    'spark.yarn.maxAppAttempts': '1'}},\n  'parallelTask': {'maxRetriesPerWorker': 0,\n   'workerCountPerNode': 1,\n   'terminalExitCodes': None,\n   'configuration': {}},\n  'amlCompute': {'name': None,\n   'vmSize': None,\n   'retainCluster': False,\n   'clusterMaxNodeCount': None},\n  'aiSuperComputer': {'instanceType': 'D2',\n   'imageVersion': 'pytorch-1.7.0',\n   'location': None,\n   'aiSuperComputerStorageData': None,\n   'interactive': False,\n   'scalePolicy': None,\n   'virtualClusterArmId': None,\n   'tensorboardLogDirectory': None,\n   'sshPublicKey': None,\n   'sshPublicKeys': None,\n   'enableAzmlInt': True,\n   'priority': 'Medium',\n   'slaTier': 'Standard',\n   'userAlias': None},\n  'kubernetesCompute': {'instanceType': None},\n  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n  'mpi': {'processCountPerNode': 1},\n  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n  'hdi': {'yarnDeployMode': 'Cluster'},\n  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n  'exposedPorts': None,\n  'docker': {'useDocker': True,\n   'sharedVolumes': True,\n   'shmSize': '2g',\n   'arguments': []},\n  'cmk8sCompute': {'configuration': {}},\n  'commandReturnCodeConfig': {'returnCode': 'Zero',\n   'successfulReturnCodes': []},\n  'environmentVariables': {},\n  'applicationEndpoints': {},\n  'parameters': []},\n 'logFiles': {'azureml-logs/60_control_log.txt': 'https://exercisedeepne4107602632.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes-mlflow_1665911211_cd522cb6/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=r%2FqE%2FGiShtmbyTTe5ZsL3gNXFNC6Zai60X9VxzhrnRk%3D&skoid=f7312be2-3e76-4d30-b80f-d3839b51041e&sktid=d6755233-46af-4030-8906-057bd29a9ee8&skt=2022-10-16T08%3A47%3A10Z&ske=2022-10-17T16%3A57%3A10Z&sks=b&skv=2019-07-07&st=2022-10-16T08%3A56%3A58Z&se=2022-10-16T17%3A06%3A58Z&sp=r',\n  'azureml-logs/70_driver_log.txt': 'https://exercisedeepne4107602632.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes-mlflow_1665911211_cd522cb6/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=4z4LD8XUTRHaojEofsGtx89Dc12JHewrvmj2T0jhQus%3D&skoid=f7312be2-3e76-4d30-b80f-d3839b51041e&sktid=d6755233-46af-4030-8906-057bd29a9ee8&skt=2022-10-16T08%3A47%3A10Z&ske=2022-10-17T16%3A57%3A10Z&sks=b&skv=2019-07-07&st=2022-10-16T08%3A56%3A58Z&se=2022-10-16T17%3A06%3A58Z&sp=r',\n  'logs/azureml/7_azureml.log': 'https://exercisedeepne4107602632.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes-mlflow_1665911211_cd522cb6/logs/azureml/7_azureml.log?sv=2019-07-07&sr=b&sig=GNV1KzrNJFuUHDoIDDNgvpTg0o85QGdA%2FtO5i7IGLZg%3D&skoid=f7312be2-3e76-4d30-b80f-d3839b51041e&sktid=d6755233-46af-4030-8906-057bd29a9ee8&skt=2022-10-16T08%3A47%3A10Z&ske=2022-10-17T16%3A57%3A10Z&sks=b&skv=2019-07-07&st=2022-10-16T08%3A56%3A58Z&se=2022-10-16T17%3A06%3A58Z&sp=r'},\n 'submittedBy': '형진 김'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1665911218931
        },
        "scrolled": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As usual, you can get the logged metrics from the experiment run when it's finished."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get logged metrics\n",
        "metrics = run.get_metrics()\n",
        "for key in metrics.keys():\n",
        "        print(key, metrics.get(key))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "observations 10000.0\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1665911219357
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **More Information**: To find out more about running experiments, see [this topic](https://docs.microsoft.com/azure/machine-learning/how-to-manage-runs) in the Azure ML documentation. For details of how to log metrics in a run, see [this topic](https://docs.microsoft.com/azure/machine-learning/how-to-track-experiments). For more information about integrating Azure ML experiments with MLflow, see [this topic](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-mlflow)."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}